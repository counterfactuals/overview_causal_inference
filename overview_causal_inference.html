<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>A Brief Overview of Causal Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Todd R. Johnson, PhD   Professor      tjohnson250     @johnsontoddr4    todd.r.johnson@uth.tmc.edu" />
    <meta name="date" content="2019-06-30" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/jquery/jquery.min.js"></script>
    <link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding/datatables.js"></script>
    <link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <script src="libs/viz/viz.js"></script>
    <link href="libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="libs/grViz-binding/grViz.js"></script>
    <script src="libs/pymjs/pym.v1.js"></script>
    <script src="libs/widgetframe-binding/widgetframe.js"></script>
    <script src="https://kit.fontawesome.com/08ea13597f.js"></script>
    <link rel="stylesheet" href="my-fonts.css" type="text/css" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# A Brief Overview of Causal Inference
### Todd R. Johnson, PhD <br> Professor <br><br> <a href="https://github.com/tjohnson250"><i class="fab fa-github fa-fw"></i>  tjohnson250</a><br> <a href="https://twitter.com/johnsontoddr4"> <i class="fab fa-twitter fa-fw"></i>  <span class="citation">@johnsontoddr4</span></a><br> <a href="mailto:todd.r.johnson@uth.tmc.edu"><i class="fa fa-paper-plane fa-fw"></i>  todd.r.johnson@uth.tmc.edu</a><br><br>
### The University of Texas School of Biomedical Informatics at Houston
### 2019-06-30

---




# Disclaimer

Use the arrow keys to navigate. Press .key[h] `h` for help. To see speaker notes, press `p` to enter presentation mode. 

This is unfinished work. My primary objective for creating this presentation is to help me understand the basics of causal infererence. I hope to use it to help others as well, especially machine learning researchers who tend to make predictive, rather than causal models.

This presentation is hosted on Github Pages at: https://tjohnson250.github.io/overview_causal_infererence/overview_causal_infererence.html#1

The source code to generate the presentation is at: https://github.com/tjohnson250/overview_causal_infererence

If you find errors or have suggestions for improvement, open an issue on this project's Github repo.

---
# Pearl's Three Layer Causal Hierarchy

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Level &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Typical.Activity &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Typical.Questions &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Examples &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 1. Association&lt;br&gt;\(\mathbf{P(y|x)}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Seeing &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; What is?&lt;br&gt;How would seeing X change my belief in Y? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; What does a symptom tell me about a disease?&lt;br&gt;What does a survey tell us about the election results? &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 2. Intervention&lt;br&gt;\(\mathbf{P(y|do(x), z)}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Doing,&lt;br&gt;Intervening &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; What if?&lt;br&gt;What if I do X? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; What if I take aspirin, will my headache be cured?&lt;br&gt;What if we ban cigarettes? &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 3. Counterfactuals&lt;br&gt;\(\mathbf{P(y_x|x',y')}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Imagining,&lt;br&gt;Retrospecting &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Why?&lt;br&gt;Was it X that caused Y?&lt;br&gt;What if I had acted differently? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Was it the aspirin that stopped my headache?&lt;br&gt;Would Kennedy be alive had Oswald not shot him?&lt;br&gt;What if I had not been smoking the past 2 years? &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
class: middle

### Part I: Causation

### Part II: Identifying and Estimating Causal Effects from Observational Data

### Part III: Causal Model Evaluation

### Part IV: Causal Discovery from Observational Data

### Part V: Counterfactual Reasoning

---
class: center, middle

# Part I: Causation

---

# Definitions

**Causal Infererence** is the process of inferring the **causal effect** of one random variable on a second random variable.

The **Causal Effect** of `\(X\)` on `\(Y\)` is the change in `\(Y\)` when we **intervene** and directly change `\(X\)` from one value to another.

**Intervening** on `\(X\)` means to force `\(X\)` to take a specific value, independent of any of the variables that normally influence the value of `\(X\)`

 - Suppose that the decision to treat is normally influenced only by gender, *intervening* means ignoring gender when deciding on treatment, such as by randomly assigning whether to treat or not  
  
 - This is why RCTs are considered the gold standard for identifying causal effects

---
# Example: Age, Exercise and Cholesterol
Suppose that the following model accurately describes how age, exercise, and cholesterol are related

.pull-left[

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
e &lt;- 0.3*a + rnorm(n)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
]

.pull-right[
From the model, the causal effect of exercise on cholesterol is `\(-1e\)`:

  - For every unit increase in excercise, cholesterol decreases by `\(1\)`
  
Causal DAG (Directed Acyclic Graph)
  - Graphical representation of the data generating model
  - Links represent *possible* direct causal effects
  - Missing links indicate the strong assumption of no direct causal effect
  - Must include all common causes of any pair of variables already in the DAG
]

---
## Intervening Changes the Generative Model
Intervene by randomly setting `\(E\)` from `\(0 - 20\)`
.pull-left[
### Observational Model

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
*e &lt;- 0.3*a + rnorm(n)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

.pull-right[
### Interventional Model

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
*e &lt;- sample(0:20, n, replace = TRUE)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
]

---
## Intervening Changes The Distribution

.pull-left[
### Observational Distribution
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-6-1.png" width="70%" /&gt;

`\(c = 102.53+0.49e \space (p&lt;.001)\)`
]

--

.pull-right[
### Interventional Distribution
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-7-1.png" width="70%" /&gt;

`\(c = 124.86+-0.99e \space (p&lt;.001)\)`
]

???
The coefficient for `\(e\)` on the observational distribution is way off, but the coefficient for the interventional distribution is close. Both coefficents are statistically significant at the p = .001 level.

---
# Difference Between Seeing and Doing
.pull-left[
### Observational Association
`\(E(C|e)\)`: The expected value of Cholesterol given that we observe a specific level of exercise.

`\(E(C|e)\)` is confounded, because age `\(A\)` affects both the amount of exercise `\(E\)` a person gets and cholesterol levels `\(C\)`.
]
.pull-right[
### Interventional Association (Causal Effect)
`\(E(C|do(e))\)`: The expected value of Cholesterol given that we intervene and set exercise to a specific value, independent of any of the variables that normally influence the value of `\(E\)`.

`\(do()\)` is called the do-operator.
]

---
### Average Causal Effect (ACE) for a Population
Contrast of the mean values of `\(Y\)` (outcome) given two specific interventions on `\(X\)` (treatment)

- Dichotomous (binary) outcomes: 

    `$$P(Y=1|do(X = 1)-P(Y=1|do(X = 0)))$$`
    
    `$$P(Survival|do(Treat))-P(Survival|do(Don't Treat))$$`

- Continuous outcomes:  

    `$$E(Y|do(X=x)) - E(Y|do(X=x^{\prime})$$`

First equation is a special case, since for dichotomous outcomes 
  `$$E(Y|do(X=x)) = P(Y=1|do(X = x))$$`
???
ACE is also called the Average Treatment Effect (ATE)

Contrast ACE with the individual causal effect: the difference between counterfactual outcomes for a single patient--the outcome if treated vs. the outcome if not treated. Lack of an average causal effect does not imply lack of an individual causal effect. However, in most cases it is impossible to estimate individual causal effects from observational data because we only ever observe the effect of one level of the treatment for an individual. 

A crossover randomized experiment in which we give different treatments over time to the same person can sometimes measure individual causal effects when treatment and outcome are short term and do not affect the next treatment period. This is commonly used in cognitive science  and psychology in within-subject designs. For example, we might measure a subject's ability to monitor different numbers of patients using a telemonitoring system to determine the effect of patient load on time to respond to events, error rate, etc.

See Hernan and Robbins, Causal Inference, Chapter 1 and Fine Point 2.1 for more details in individual vs. population causal effects. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/

---
## Estimating ACE of Exercise on Cholesterol Using the Interventional Dataset
Step 1: Estimate functional relationship between C and E using linear regression on the **interventional dataset**:



`$$c = 124.86+-0.99e \space (p&lt;.001)$$`

`$$E(C|do(E=e))=124.86+-0.99e \space (p&lt;.001)$$`

Step 2: Use regression equation to calculate ACE

$$
`\begin{align}
  ACE &amp;= E(Y|do(E=1))-E(Y|do(E=2)) \\
      &amp;= (124.86+-0.99*1) - (124.86+-0.99*2) \\
      &amp;= 122.87 - 123.87 \\
      &amp;= -0.99
\end{align}`
$$
Equivalently: The regression coefficent on `\(e\)` directly tells us how much `\(C\)` will change for each unit increase in `\(E\)`.

---
class: center, middle, Large

We say that `\(\mathbf{X}\)` **causes** `\(\mathbf{Y}\)` in a population when the **average causal effect** of `\(X\)` on `\(Y\)` is non-zero.

---
class: center, middle

## Part II: Identifying and Estimating Causal Effects from
## Observational Data

---
## With Observational Data...
.pull-left[
#### using E to predict C gives an incorrect estimate,
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-9-1.png" width="70%" /&gt;

`\(c = 102.53+0.49e \space (p&lt;.001)\)`
]

--

.pull-right[
#### but controlling for C gives the correct estimate
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-10-1.png" width="70%" /&gt;

`\(c = 99.91+-1.01e + 0.5a \space (p&lt;.001)\)`
]
???
The graph on the right shows the observational data with a regression line for each of several age groups. As you can see, most of the lines show the appropriate negative correlation between `\(C\)` and `\(E\)`. Lines near the left and right are incorrect due to sparse data. Stratifying by age (here age group) is one method for controlling or adjusting for a confounder, such as `\(A\)`.

The regression equation also shows a very close estimate of the correct causal effect of `\(E\)` on `\(C\)`. Regressing `\(C\)` on both `\(E\)` and `\(A\)` controls or adjusts for `\(A\)`, returning the close estimate of the true causal effect of `\(E\)` on `\(C\)`.

---
## Adjustment
Stratifying by age `\((A)\)` or including `\(A\)` as a covariate in the regression `\((C = {\beta_1}+{\beta_2}A + {\beta_3}E)\)` is called **adjusting**, **conditioning**, or **controlling for A**

In R code, regression using the observational dataset (`dobs`):
.pull-left[
Unadjusted for `\(A\)`

```r
lm(C ~ E, dobs)
```

```
## 
## Call:
## lm(formula = C ~ E, data = dobs)
## 
## Coefficients:
## (Intercept)            E  
##    102.5273       0.4911
```
]
.pull-right[
Adjusted for `\(A\)`

```r
lm(C ~ E + A, dobs)
```

```
## 
## Call:
## lm(formula = C ~ E + A, data = dobs)
## 
## Coefficients:
## (Intercept)            E            A  
##     99.9105      -1.0115       0.5031
```
]
---
### What is the Causal Effect of Age on Cholesterol?
Using the observational dataset, regressing `\(C\)` on `\(A\)` and `\(E\)` gave us: `\(c = 99.91+-1.01e + 0.5a\)`
.pull-left[

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
e &lt;- 0.3*a + rnorm(n)
*c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;
]
.pull-right[
From the model, the **direct causal effect** of `\(A\)` on `\(C\)` is `\(0.5a\)`

  - Regressing `\(C\)` on `\(A\)` and `\(E\)` closely estimates this effect.

  - However `\(A\)` also affects `\(C\)` through `\(E\)`

The **total causal effect** of `\(A\)` on `\(C\)` includes the effect of `\(A\)` through both paths,  which from the model is:

$$
`\begin{align}
  c &amp;= .5a + -1\mathbf{e} \\
    &amp;= 0.5a + -1\mathbf{(0.3a)} \\
      &amp;= 0.5a\mathbf{- 0.3a} \\
      &amp;= 0.2a \\
\end{align}`
$$

]

---
### A Single Analysis is Usually Insuffient to Measure All Effects
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-15-1.png" width="70%" /&gt;

`\(c = 99.97+0.2a \space (p&lt;.001)\)`
]
.pull-right[
This simple 3 variable dataset requires two different regression analyses to estimate the causal effects of `\(A\)` on `\(C\)` and `\(E\)` on `\(C\)`
  
- Total effect of `\(E\)`, Direct effect of `\(A\)`:

    `\(c = 99.91+-1.01e + 0.5a \space (p&lt;.001)\)`

-  Total effect of `\(A\)`:

    `\(c = 99.97+0.2a \space (p&lt;.001)\)`
  
Simply throwing all covariates into a single regression is insufficient... but this is what most machine learning models do
]
???
To get the direct effect of `\(A\)` and `\(E\)` (thereby estimating all path coefficients) we would have to regress `\(E\)` on `\(A\)`. Later slides show that we don't need to adjust for `\(C\)` because it is a collider. Adjusting for `\(C\)` would give an incorrect estimate of the effect of `\(A\)` on `\(E\)`.

---
class: center, middle

.Large[How do we know when and what to adjust for?]

---
## Paths in Causal DAGs
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-16-1.png" width="70%" /&gt;
]
.pull-right[
A **path** is a sequence of non-intersecting adjacent edges
  - Non-intersecting means a path cannot cross a node more than once
  - Direction of the arrows doesn't matter

Examples:
  - `\(A \rightarrow E\)`
  - `\(A \rightarrow E \rightarrow C\)`
  - `\(E \leftarrow A \rightarrow C\)`
  
All associations are transmitted along paths,
but not all paths transmit association!
]

???
Source: https://www.ssc.wisc.edu/~felwert/causality/wp-content/uploads/2013/06/2-elwert_dags.pdf
See here for how to cite sources using refmanager package: https://github.com/yihui/xaringan/wiki/Bibliography-and-citations

---
class: center, middle
.Large[Two Kinds of Paths: **Causal** and **Non-Causal**]

---
## Causal Paths
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-17-1.png" width="70%" /&gt;
]
.pull-right[
**Causal Path:** A path in which all arrows point away from the treatment to the outcome
 - Causal path for Treatment `\(E\)` and Outcome `\(C\)`
    * `\(E \rightarrow C\)`
  
 - Causal paths for Treatment `\(A\)` and Outcome `\(C\)`
    * `\(A \rightarrow E \rightarrow C\)`
    * `\(A \rightarrow C\)`
    
The **total causal effect** of a treatment on an outcome consists of association transmitted along all causal paths connecting them
]

---
## Non-Causal Paths
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-18-1.png" width="70%" /&gt;
]
.pull-right[
**Non-Causal Path:** A path from the treatment to the outcome in which at least one arrow points back to the treatment
 - Non-Causal path for Treatment E and Outcome C
    * `\(E \leftarrow A \rightarrow C\)`
  
 - Non-Causal paths for Treatment `\(A\)` and Outcome C
    * None
    
Non-causal paths are potential spurious sources of association between treatment and outcome
]

---
### Causal and Non-Causal Paths for Treatment E and Outcome C
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-19-1.png" width="70%" /&gt;
]
.pull-right[
Causal path:
  - `\(E \rightarrow C\)`
  
Non-Causal path:
  - `\(E \leftarrow A \rightarrow C\)`

    
The non-causal path is a source of confounding because it transmits spurious association between `\(E\)` and `\(C\)`

Adjusting for `\(A\)` in the observational data blocks this path, allowing us to use the observational data to estimate the causal effect of `\(E\)` on `\(C\)`
]

---
## Identifiability
A causal effect is **identifiable** if the controlled (post-intervention) distribution can be estimated from data drawn from the observational (pre-intervention) distribution.

The **Backdoor Criterion** is one identification method:

The causal effect of `\(T\)` on `\(Y\)` is **identifiable** if
we can adjust for a set of variables that

 - blocks all non-causal paths between `\(T\)` and `\(Y\)`
 - without blocking any causal paths between `\(T\)` and `\(Y\)`

---
### Blocking and Unblocking Paths
All Causal DAGs are a combination of these three patterns:

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-20-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-21-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-22-1.png" width="70%" /&gt;
]
.pull-right[
**Linear Path (or Chain)**

  - Adjusting for `\(E\)` (a mediator) *blocks* the path between `\(A\)` and `\(C\)`

**Common Cause**

  - Adjusting for `\(A\)` *blocks* the path between `\(E\)` and `\(C\)`

`$$\space$$`

**Common Effect**

  - `\(C\)` is called a collider
  - Unadjusted colliders *block* the path
  - Adjusting for `\(C\)` (or a descendent of `\(C\)`)  **unblocks or opens** the path
]

---
## Identifying the Total Effect of `\(A\)` on `\(C\)`
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-23-1.png" width="70%" /&gt;
]
.pull-right[
**Total Effect of `\(A\)` on `\(C\)`**

No adjustments needed

  - All paths from `\(A\)` to `\(C\)` are causal

  * `\(A \rightarrow C\)`
  * `\(A \rightarrow E \rightarrow C\)`

**Direct Effect of `\(A\)` on `\(C\)`**

Adjusting for `\(E\)` blocks the path `\(A \rightarrow E \rightarrow C\)` leaving only the direct path `\(A \rightarrow C\)`
]

---
## Identifying the Total Effect of `\(A\)` on `\(E\)`
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-24-1.png" width="70%" /&gt;
]
.pull-right[
**Total (and Direct) Effect of `\(A\)` on `\(E\)`**

No adjustments needed

  * Causal path

    - `\(A \rightarrow E\)`

  * Non-causal path, blocked by collider `\(C\)`
  
    - `\(A \rightarrow C \leftarrow  E\)`
    
    - Adjusting for `\(C\)` would distort the effect estimate
]

---
## Backdoor Criterion (Pearl 1995)
A set of variables `\(\{Z\}\)` (possibly empty) satisfies the **backdoor criterion** relative to an ordered pair of variables `\(\{X, Y\}\)` in a DAG if:

  1. no node in `\(\{Z\}\)` is a descendent of `\(X\)`, and
  
  2. `\(\{Z\}\)` blocks every path between `\(X\)` and `\(Y\)` that contain an arrow into `\(X\)` (the "backdoor paths")
  
If `\(\{Z\}\)` meets the backdoor criterion, the total causal effect of `\(X\)` on `\(Y\)` is non-parametrically identifiable given `\(\{Z\}\)`, such that:

$$ P(Y|do(X)) = \sum_{Z} P(Y|X,Z)P(Z)$$

The backdoor criterion recognizes that all paths that descend from `\(X\)` are either causal or blocked
---

## Multiple Adjustment Sets
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-25-1.png" width="70%" /&gt;
]
.pull-right[
Adjustment sets for `\(X \rightarrow Y\)`:


```
##  { W1, W2, Z2 }
##  { V, W1, W2 }
##  { W1, W2, Z1 }
```

Adjusting for any one of these sets of variables eliminates confouding for the causal effect of `\(X\)` on `\(Y\)`

For a linear model this means regressing `\(Y\)` on `\(X\)`, including as covariates only one set of these variables 

In R, any of these statements will estimate the total effect of `\(X\)` on `\(Y\)` from observational data `obsdata`:


```r
lm(obsdata, Y ~ X + W1 + W2 + Z2)
lm(obsdata, Y ~ X + V + W1 + W2)
lm(obsdata, Y ~ X + W1 + W2 + Z1)
```
]

---
# Adjustment Sets for `\(X \rightarrow Y\)`

![](overview_causal_inference_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;
???
Bold edges are unadjusted, light edges are adjusted

The backdoor criterion implicitly prevents adjusting for children of mediators. For instance, suppose we want to determine the causal effect of `\(X\)` on `\(Y\)` in the model:

`$$X \rightarrow Z \rightarrow Y$$`
`$$Z \rightarrow Z_2$$`
where `\(Z\)`, a mediator, causes `\(Z_2\)`. It is clear that adjusting for `\(Z\)` would block the path between `\(X\)` and `\(Y\)`, but adjusting for `\(Z_2\)` would partially block the path.

---
# Frontdoor Adjustment Criterion
.pull-left[
U unmeasured: Cannot block backdoor path from `\(X \rightarrow Y\)`

&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-29-1.png" width="70%" /&gt;
]
.pull-right[
`\(X \rightarrow Y\)` is still identifiable using a two step process:

Step 1. Identify `\(X \rightarrow Z\)`:

  * Backdoor path blocked by collider `\(Y\)`
  
`$$X \leftarrow U \rightarrow Y \leftarrow Z$$`
  * In R: `lm(obsdata, Z ~ X)`
  
Step 2. Identify `\(Z \rightarrow Y\)`:

  * Backdoor path blocked by adjusting for `\(X\)`

`$$Z \leftarrow X \leftarrow U \rightarrow Y$$`
  * In R: `lm(obsdata, Y ~ Z + X)`
]
???
Since `\(U\)` is unmeasured, we cannot adjust for it. However, in this case, the frontdoor adjustment criterion allows us to identify the causal effect of `\(X\)` on `\(Y\)` in two steps.
---
## Frontdoor Adjustment Criterion (Pearl 1995)
A set of variables `\(\{Z\}\)` satisfies the **frontdoor criterion** relative to an ordered pair of variables `\(\{X, Y\}\)` in a DAG if:

  1. `\(\{Z\}\)` intercepts all directed paths from `\(X\)` to `\(Y\)`,
  
  2. there is no backdoor path between `\(X\)` and `\(Z\)`,
  
  3. every backdoor path between `\(Z\)` and `\(Y\)` is blocked by `\(X\)`
  
If `\(\{Z\}\)` meets the frontdoor criterion, the causal effect of `\(X\)` on `\(Y\)` is identifiable given `\(\{Z\}\)`, such that:

`$$P(y|do(x)) = \sum_{z} P(z|x)\sum_{x'}P(y|x', z)P(x')$$`

`\(x\)` is the value of `\(X\)` in `\(do(x)\)`, `\(x'\)` refers to all values of `\(X\)`

---
## Instrumental Variables
Instrumental variables are those that only affect the treatment, with no relationship to anything else

---
# Identifying Covariate Specific Effects
Suppose a drug `\(D\)` affects `\(C\)`, gender `\(G\)` affects who takes the drug.

.pull-left[
What is the effect of `\(E\)` on `\(C\)` when we *observe* `\(D = d\)`?
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-30-1.png" width="70%" /&gt;
]
.pull-right[
Estimate `\(P(C=c|do(E=e), D=d)\)`


Must use an adjustment set `\({S} \cup D\)` that blocks all backdoor paths from `\(E\)` to `\(C\)`.

No need to block backdoor path from `\(D\)` to `\(C\)`.

Valid adjustment set: `\({A, D}\)`

Regression: `lm(obsdata, C ~ A + D)`

Mathematically:

`$$\begin{aligned} P(Y=y&amp;|do(X=x), Z=z) = \\  &amp;\sum_S P(Y=y|X=x, S=s, Z=z)P(S=s|Z=z) \end{aligned}$$`

]
???
Note that the summation in the adjustment formula is over `\(S\)`, not `\(S \cup Z\)`. `\(S\)` is the set of all the other variables needed to block the backdoor paths from `\(X\)` to `\(Y\)`.

We don't want to block the backdoor path from `\(D\)` to `\(C\)` here, because the query is asking for the effect of `\(E\)` on `\(C\)` when we intervene on `\(E\)` and then in the resulting interventional distribution observe `\(D=d\)`.

In contrast, if we just want to identify `\(P(Y=y|do(X=x))\)` we have:

`$$P(Y=y|do(X=x)) = P(Y=y|X=x, S=s)P(S=s)$$`

where `\(S\)` is a valid adjustment set that blocks the backdoor paths from `\(X\)` to `\(Y\)`.

The basic idea is that when we look at the interventional distribution (resulting from adjusting for `\(S\)`), we must stratify by `\(Z\)` to compute the covariate-specific effect, which means we are also adjusting for `\(Z\)`. Thus we have to make sure that adjusting for `\(Z\)` does not open any backdoor paths for the effect from `\(X\)` to `\(Y\)`.]

---
### Identifying the Effects of Multiple Interventions
What is the effect of simultaneously intervening on `\(X\)` and `\(Z2\)`?
.pull-left[
What is the effect of `\(E\)` on `\(C\)` when we *observe* `\(D = d\)`?
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-31-1.png" width="70%" /&gt;
]
.pull-right[
Estimate `\(P(C=c|do(E=e, D=d))\)`

Must use an adjustment set that blocks all backdoor paths from `\(E\)` to `\(C\)` and `\(D\)` to `\(C\)`


```
##  { A, G }
```
Regression: `lm(C ~ E + A + D + G)`

Mathematically:

`$$\begin{aligned} P(Y=y&amp;|do(X=x, Z=z)) = \\  &amp;\sum_S P(Y=y|X=x, Z=z, S=s)P(S=s) \end{aligned}$$`
]
???
To estimate the effect of simultaneously intervening on `\(X\)` and `\(Z2\)`, we need an adjustment set that blocks all backdoor paths for both variables.

In this case the regression must include `\(X\)` and `\(Z2\)`:

```r
lm(Y ~ X + W1 + W2 + Z2)
```

Here, we can use the same regression equation as the previous covariate-specific example. But consider `\(P(y|do(x,w1))\)` vs. `\(P(y|do(x), w1)\)`.

The adjustment set for `\(P(y|do(w1,z1))\)` is:

```
##  { W1 }
```
The regression is:

```r
lm(Y ~ W1 + Z1 + V)
```
The adjustment sets for `\(P(y|do(w1), z1)\)` are:

```
##  {}
```

---
## Confounding is a Causal Concept

* The data alone are insufficient to identify confounders or control for confouding
* Without a causal model, observational data is limited to associational models that do not tell us how to intervene
  + This includes all common machine learning and statistical approaches
  + Example: If an associational predictive model finds a few highly predictive "risk factors" we cannot assume that intervening on those risk factors will decrease risk.
  + Variables that increase the predictive power of an associational model may include effects of the outcome, such as symptoms of a disease you are trying to predict
* Associational predictive models are still useful if we already have interventions that are known to work
  + If we know that a treatment works if given earlier in the course of a disease, better predictive models can tell us who to treat

---
class: center, middle, Large

Causal Inference Requires a Causal Model,

But...

How Do we Know if Our Model is Correct?
---
class: center, middle
# Part III: Model Evaluation

---
# Two Approaches to Model Evaluation
Local fit tests

- Tests of model-implied conditional independence assumptions

Global fit tests

- Model chi-square: comparison of model vs. observed covariance matrices)

- RMSEA: Root Mean Square Error of Approximation

- CFI: Comparative fit index

- SRMSR: Standaridzed Root Mean Square Residual
???
From: Kline RB. Principles and practice of structural equation modeling. Guilford publications; 2015 Nov 3.
---
## Model Evaluation: Local Fit Tests
Causal DAG's imply independence relations

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-37-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-38-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-39-1.png" width="70%" /&gt;
]
.pull-right[
**Linear Path (or Chain)**

  - `\(A \perp\!\!\!\perp C | E\)`



**Common Cause**

  - `\(E  \perp\!\!\!\perp  C | A\)`

`$$\space$$`
`$$\space$$`

**Common Effect**

  - `\(A  \perp\!\!\!\perp  E\)`
  - `\(A  \not\!\perp\!\!\!\perp  E | C\)`
]

---
## Example: Age, Gender, BMI and Cholesterol
.small[Causal DAG Implied by Gostynski M, Gutzwiller F, Kuulasmaa K, Döring A, Ferrario M, Grafnetter D, Pajak A. **Analysis of the relationship between total cholesterol, age, body mass index among males and females in the WHO MONICA Project.** *International Journal of Obesity.* 2004 Aug;28(8):1082.]

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-40-1.png" width="70%" /&gt;
]

.pull-right[
This Causal DAG implies the following conditional independencies

.scroll-box-8[

```
bmigrp _||_ eageg | height, weight
bmigrp _||_ sex | height, weight
eageg _||_ height
eageg _||_ sex
height _||_ hychol | bmigrp, eageg, sex
hychol _||_ weight | bmigrp, eageg, sex
```
]

Given data on these variables, we can test for these statistical relationships.
]

---
### Testing Implied Independencies with Observed Data

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-42-1.png" width="70%" /&gt;
]

.pull-right[
Independence tests for all implied independencies based on 17440 participants:


<div id="htmlwidget-e2c967d9ebc57f0db942" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e2c967d9ebc57f0db942">{"x":{"filter":"none","fillContainer":false,"data":[["bmigrp _||_ eageg | height, weight","bmigrp _||_ sex | height, weight","eageg _||_ height","eageg _||_ sex","height _||_ hychol | bmigrp, eageg, sex","hychol _||_ weight | bmigrp, eageg, sex"],[0.0130031546385232,-0.017136283212477,-2.19489596560299,-2.672352570735e-05,-0.00138660727127573,0.00100917415354059],[2.13804203310127e-06,0.0585862658646039,4.1824828237127e-142,0.998672916422782,0.458122403906288,0.0585862658646039]],"container":"<table class=\"nowrap hover\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":3,"dom":"tp","order":[[2,"asc"]],"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"autoWidth":false,"orderClasses":false,"lengthMenu":[3,10,25,50,100],"rowCallback":"function(row, data) {\nDTWidget.formatRound(this, row, data, 1, 2, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 2, 2, 3, ',', '.');\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
]

???
The table is sorted in increasing order by `p.values`

`p.values` were corrected for multiple comparisons using the Holm-Bonferroni method

The null hypothesis is that the estimate is 0, which would indicate independence, so if `\(p &lt; .05\)` we can reject the null, meaning that the indpendence implication is unlikely to be true.

See Figure 1 in http://johannes-textor.name/papers/2017-ije.pdf for details (Textor J, van der Zander B, Gilthorpe MS, Liśkiewicz M, Ellison GT. Robust causal inference using directed acyclic graphs: the R package ‘dagitty’. *International journal of epidemiology.* 2016 Dec 1;45(6):1887-94.)

Tests for independence are linear in the dagitty package. Distance Correlation can detect non-linear independence For example:


```r
library(energy) # provides test for marginal independence using distance correlation 

# Tests show probability of independence
# Low p values indicate dependence

#  Distance correlation is computationally intensive $O(n^2)$ and memory intensive, so use a random sample of data
monicasamp &lt;- sample_n(monica, 1000)
dcor.ttest(monica$eage, monica$sex) # marginally independent

# Independence under partial correlation (whether distance or linear) is not identical to conditional independence. 
# The CDCSIS package (below) tests for conditional independence using distance correlation, whereas the energy package (above) only tests for partial distance correlation. 
# If all variables are multivariate gaussian, the partial linear correlation is 0 if and only if  X and Y are conditionally linearly independent given Z, but otherwise this is not true. 
# See the following paper for more details on the relationship between conditional independence of partial correlation: https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2004.00360.x

# See section 4.3 of (http://real.mtak.hu/44934/1/pdcov.pdf) Székely GJ, Rizzo ML. Partial distance correlation with methods for dissimilarities. The Annals of Statistics. 2014;42(6):2382-412.

# Test independence under partial correlation independence hypothesis using distance correlation. 
pdcor.test(monicasamp$bmigrp, monicasamp$weight, monicasamp$bmi, R=99) # Dependent although model implies independence

library(cdcsis) # Provides cdcsis and cdcsis.test for conditional distance correlation

# compute conditional distance correlation 
cdcsis(as.matrix(monicasamp$bmigrp), monicasamp$weight, as.matrix(monicasamp$bmi), threshold = 1) # must give threshold here as 1 for this data
# Test conditional independence hypothesis using distance correlation
cdcov.test(as.matrix(monicasamp$bmigrp), monicasamp$weight, as.matrix(monicasamp$bmi)) # Dependent at the .05 level, but not .01
```

---
# Coefficients where `\(p &lt; .05\)`

.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-45-1.png)&lt;!-- --&gt;
]

.pull-right[
The data suggests that `\(eage\)` and `\(height\)` are *not* marginally independent

This contradicts our model
]
---
## Add `\(eage \rightarrow height\)` and Retest

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-46-1.png" width="70%" /&gt;
]

.pull-right[
Coefficients where `\(p &lt; .05\)`

![](overview_causal_inference_files/figure-html/unnamed-chunk-47-1.png)&lt;!-- --&gt;
]
---
## Summarizing Independence Tests: Fisher's C
- Statistical test of the set of independence test results

`$$C = -2\sum \ln p_i$$`
 - `\(p_i\)` are the `\(p\)`-values of all tests of conditional independence for the **basis set**
- **Basis Set**: the smallest set of independence relations implied by a DAG

```r
# Use package dagitty to return the basis set
library(dagitty)
impliedConditionalIndependencies(dag)
```

- `\(C\)` has a `\(\chi^2\)` distribution with `\(2k\)` degrees of freedom, where `\(k\)` is the number of elements in the basis set

 - `\(p \geq .05\)` is good
 - If `\(p &lt; .05\)` reject model, consider alternatives: more links, different structure, etc.

- For the WHO MONICA DAG: `\(C\)` = 26.11, `\(p\)` = 0
???
To calculate `\(C\)` and the `\(\chi^2\)` `\(p\)`-value in R, given that the `\(p\)`-values for the WHO MONICA DAG are in `r$p.value`:

```r
C = -2*sum(log(r$p.value))
k = length(r$p.value) # Number of tests in basis set
p = 1 - pchisq(C, 2 * k)
cat("p = ", p)
```

```
## p =  2.138042e-06
```
           
---
# Limitations
- Most packages only detect (lack of) linear dependence
 - Independent variables are guaranteed to have `\(0\)` correlation
 - But `\(0\)` correlation does not imply independence when the relatinship is nonlinear
 - A Partial correlation of `\(0\)` (for conditional independence) implies conditional independence only when the joint distribution of the tested variables is multinormal
 
- Distance correlation (Szekely, et al. 2007) and conditional distance correlation (Wang, et al., 2015) can detect nonlinear dependence
 - But complexity is at worst `\(\mathcal{O}(n^2)\)` and at best `\(\mathcal{O}(n\log n)\)` (Chaudhuri and Hu, 2019)
 
???
 Székely GJ, Rizzo ML, Bakirov NK. Measuring and testing dependence by correlation of distances. The annals of statistics. 2007;35(6):2769-94.
 
  Wang X, Pan W, Hu W, Tian Y, Zhang H. Conditional distance correlation. Journal of the American Statistical Association. 2015 Oct 2;110(512):1726-34.
 
 Chaudhuri A, Hu W. A fast algorithm for computing distance correlation. Computational Statistics &amp; Data Analysis. 2019 Jul 1;135:15-24.
 
---
## Global Fit Tests



.pull-left-65[
.scroll-box-20[
All variables standardized before analysis


```
lavaan 0.6-4.1415 ended normally after 154 iterations

  Optimization method                           NLMINB
  Number of free parameters                         19

  Number of observations                         17440

  Estimator                                       DWLS      Robust
  Model Fit Test Statistic                       6.168      46.260
  Degrees of freedom                                 2           2
  P-value (Chi-square)                           0.046       0.000
  Scaling correction factor                                  0.133
  Shift parameter                                            0.018
    for simple second-order correction (Mplus variant)

Model test baseline model:

  Minimum Function Test Statistic            34299.840   27768.575
  Degrees of freedom                                 6           6
  P-value                                        0.000       0.000

User model versus baseline model:

  Comparative Fit Index (CFI)                    1.000       0.998
  Tucker-Lewis Index (TLI)                       1.000       0.995

  Robust Comparative Fit Index (CFI)                            NA
  Robust Tucker-Lewis Index (TLI)                               NA

Root Mean Square Error of Approximation:

  RMSEA                                          0.011       0.036
  90 Percent Confidence Interval          0.001  0.021       0.027  0.045
  P-value RMSEA &lt;= 0.05                          1.000       0.995

  Robust RMSEA                                                  NA
  90 Percent Confidence Interval                                NA     NA

Standardized Root Mean Square Residual:

  SRMR                                           0.003       0.003

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model        Unstructured
  Standard Errors                           Robust.sem

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  height ~                                            
    eageg            -0.194    0.006  -35.166    0.000
    sex              -0.665    0.005 -121.156    0.000
  weight ~                                            
    height            0.473    0.007   63.547    0.000
    eageg             0.217    0.007   31.177    0.000
    sex              -0.093    0.009  -10.936    0.000
  bmigrp ~                                            
    weight            4.338    4.399    0.986    0.324
    height           -2.522    2.558   -0.986    0.324
  hychol ~                                            
    bmigrp            0.040    0.040    0.986    0.324
    weight           -0.026    0.025   -1.059    0.290
    sex              -0.019    0.014   -1.328    0.184
    eageg             0.284    0.011   24.925    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .height           -0.000    0.005   -0.000    1.000
   .weight            0.000    0.007    0.000    1.000
   .bmigrp            0.000                           
   .hychol            0.000                           

Thresholds:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    bmigrp|t1        -0.503    0.511   -0.984    0.325
    bmigrp|t2         3.748    3.802    0.986    0.324
    hychol|t1         0.618    0.010   59.336    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .height            0.519    0.005  114.567    0.000
   .weight            0.705    0.006  115.482    0.000
   .bmigrp            0.259                           
   .hychol            0.985                           

Scales y*:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    bmigrp            0.271    0.275    0.986    0.324
    hychol            1.000                           
```
]
]

.pull-right-35[
Recommended levels for global fit tests

- Model `\(\chi^2\)` with df and `\(p\)`-value
 - prefer `\(p \geq .05\)`
- Comparative Fit Index
 - prefer CFI `\(&gt; 0.90\)`
- Root mean square error of Approximation
 - prefer lower 90%CI to be `\(&lt; .05\)`
- Standardized Root Mean Square Residual
 - prefer SRMR `\(&lt; 0.10\)`
]
???
Pearl argues against global fit tests because they rarely tell you where your model might be wrong. In addition, many different models can often fit the same data. He also points out that for estimating specific effects, not all of the model needs to be correct. As long as the local independence tests are valid for the effect of interest, you can still use the effect estimates.
 
---
### Visualize Mismatch between Model and Data Covariance Matrices
This shows observed - model-implied correlations
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-52-1.png" width="70%" /&gt;
---
## Examine Modification Indices
MI Indicates possible improvement in model test score

```
##       lhs op    rhs         mi       epc   sepc.lv  sepc.all  sepc.nox
## 38 height  ~ hychol   1286.251  -160.520  -160.520  -168.734  -168.734
## 39 weight  ~ bmigrp   1121.974    18.676    18.676    71.523    71.523
## 40 weight  ~ hychol 998410.444 14070.493 14070.493 14759.041 14759.041
## 41 bmigrp  ~ hychol     26.506     0.906     0.906     0.248     0.248
```

Biggest improvement would come from adding edge `\(weight \rightarrow hychol\)`, 

but `\(weight\)` is not thought to be caused by high cholesterol. 

Adding this link would violate our background knowledge.
---
## Age, Exercise, Cholesterol Model Implies No Independence Relations
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-54-1.png" width="70%" /&gt;
]
.pull-right[

```r
print( impliedConditionalIndependencies( gobs ) )
```
* C is a collider between `\(A\)` and `\(E\)`, but `\(A \rightarrow E\)` **shields** the collider, rendering `\(A\)` and `\(E\)` dependent even when `\(C\)` is not conditioned on

There are no implied independence relationships to test.
]

---
## Independence (d-separation) Equivalence
.pull-left[
Two Causal DAGs over the same set of variables are independence equivalent iff they have:

* the same adjacencies (edges between variables ignoring direction)
* the same unshielded colliders (any two nodes pointing into the collider are not adjacent)
  * In graphs 1 and 3, `\(C\)` is a *shielded* collider, because `\(A\)` and `\(E\)` have an edge between them
  * If we deleted the edge between `\(A\)` and `\(E\)`, then `\(C\)` would be an unshielded collider

These graphs are all independence equivalent.  (Verma and Pearl, 1988)
]
.pull-right[
![](overview_causal_inference_files/figure-html/unnamed-chunk-56-1.png)&lt;!-- --&gt;
]
???
This concept is explained in detail in the following lecture at around 28 minutes:

From https://www.youtube.com/watch?v=TISSNwWDfw4&amp;list=PLO5mmwQolPRX858CyOOIHqYnmdzlHjIgS&amp;index=8

(CCD Summer short course 2016:Day 2 Part 1)

---
### Completed Partially Directed Acyclic Graph (CPDAG)
.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-57-1.png)&lt;!-- --&gt;
]
.pull-right[
A CPDAG represents an equivalance class of independence equivalent graphs

* A directed edge is shared by all graphs in the class
* An undirected edge is reversible as long as no cycles or additional unshielded colliders are introduced
]

---
### Global Tests of AEC Model are Uninformative
There are 5 free parameters and 0 degrees of freedom.

.scroll-box-18[

```
## lavaan 0.6-4.1415 ended normally after 21 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                          5
## 
##   Number of observations                         10000
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                       0.000
##   Degrees of freedom                                 0
##   Minimum Function Value               0.0000000000000
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                             Standard
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   E ~                                                                   
##     A                 0.301    0.001  299.167    0.000    0.301    0.948
##   C ~                                                                   
##     A                 0.503    0.016   31.329    0.000    0.503    0.905
##     E                -1.012    0.051  -20.001    0.000   -1.012   -0.578
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .E                 1.002    0.014   70.711    0.000    1.002    0.101
##    .C                25.627    0.362   70.711    0.000   25.627    0.839
```
]

---
exclude: true
### Age, Sex, Gender, BMI, and Cholesterol
.pull-left[
Hypothesized Graph

&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-59-1.png" width="70%" /&gt;
]
.pull-right[
CPDAG

![](overview_causal_inference_files/figure-html/unnamed-chunk-60-1.png)&lt;!-- --&gt;
]

---
class: middle, center
# Part IV: Causal Discovery from Observational Data

---
# Inferring Causal Structure from Data

.center[Causal DAG `\\(\Rightarrow\\)` Independence Relations]

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-61-1.png" width="70%" /&gt;
]

.pull-right[

```
bmigrp _||_ eageg | height, weight
bmigrp _||_ sex | height, weight
eageg _||_ sex
height _||_ hychol | bmigrp, eageg, sex
hychol _||_ weight | bmigrp, eageg, sex
```
]

.center[Causal DAGS `\\(\Leftarrow\\)` Independence Relations]


---
exclude: true
### Results of the PC Algorithm (Spirtes and Glymour, 1991) On The WHO Monica Dataset 

.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-63-1.png)&lt;!-- --&gt;
]

.pull-right[
Graph implied by [Nature paper]
![](overview_causal_inference_files/figure-html/unnamed-chunk-64-1.png)&lt;!-- --&gt;
]

---
## Results of PC Algorithm on the WHO Dataset
.pull-left[
<div id="htmlwidget-df9a58adc8fa40f24805" style="width:504px;height:504px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-df9a58adc8fa40f24805">{"x":{"diagram":"digraph g {\n \"eageg\" -> \"height\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"weight\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"height\" -> \"weight\" [arrowtail=none, arrowhead=none]; \n \"height\" -> \"sex\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"bmigrp\" -> \"height\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"eageg\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"eageg\" -> \"hychol\" [arrowtail=none, arrowhead=none]; \n \"sex\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"eageg\" [dir=both, arrowtail=normal, arrowhead=none]; \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.pull-right[
Hypothesized DAG
![](overview_causal_inference_files/figure-html/unnamed-chunk-66-1.png)&lt;!-- --&gt;
]
???
The PC algorithm is one of the first causal discovery algorithms. As you can see from the inferred graph, many of the arrows are incorrect and some edges are not directional, meaning the algorithm could not orient the edge.

One limitation of PC (and most other algoirithms) is that the independence tests assume linear relationships. As a result, the algorithm will mistake nonlinearly dependent variables as independent.

See: Spirtes P, Glymour C. An algorithm for fast recovery of sparse causal graphs. Social science computer review. 1991 Apr;9(1):62-72.
---
## Adding Background Knowledge Improves Discovery


```r
# List of forbidden directed edges
forbid &lt;- list(c('chol', 'bmigrp'), c('eage', 'bmigrp'), c('sex', 'bmigrp'))

# List of required directed edges
require &lt;- list(c('height', 'bmigrp'), c('weight', 'bmigrp'))

# Forbid edges between eage and sex
forbiddenWithin &lt;- c('sex')
class(forbiddenWithin) &lt;- 'forbiddenWithin'

# Add Temporal constraints
temporal &lt;- list(forbiddenWithin, c('eageg','height', 'weight'), c('bmigrp', 'hychol')) 

prior &lt;- priorKnowledge(requiredirect = require, addtemporal = temporal, forbiddirect = forbid)
```
???
Since bmigrp is defined only by bmi, we forbid other variables from causing it. We could likewise forbid the two other defined variables in the dataset, eageg and hychol, but the algorithm works fine as is.

The temporal constraints indicate that lower tiers cannot have any directed edges to higher tiers. For instance, `bmi` and `chol` can have directed edges to `bmigrp` and `hychol`, as well as between themselves, but cannot have directed edges to the other variables that appear before them in the temporal list.
---
# PC Algorithm with Knowledge
<div id="htmlwidget-8b2f29d7321b3f592a06" style="width:504px;height:504px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-8b2f29d7321b3f592a06">{"x":{"diagram":"digraph g {\n \"eageg\" -> \"height\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"weight\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"height\" -> \"weight\" [arrowtail=none, arrowhead=none]; \n \"height\" -> \"sex\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"bmigrp\" -> \"height\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"eageg\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"eageg\" -> \"hychol\" [arrowtail=none, arrowhead=normal]; \n \"sex\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"eageg\" [dir=both, arrowtail=normal, arrowhead=none]; \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>

---
exclude: true
## Adding Knowledge: Required Edges

`TRUE` means the pair of variables must be connected by an edge



---
exclude: true
## Adding Knowledge: Forbidden Edges

A `\(1\)` means the row variable (e.g., `height`) must not have direct edge to the column variable (e.g., `bmi`)


---
exclude: true
### Results of the PC Algorithm With Background Knowledge 

.pull-left[

]

.pull-right[
Graph implied by [Nature paper]
![](overview_causal_inference_files/figure-html/unnamed-chunk-72-1.png)&lt;!-- --&gt;
]


---
class: center, middle

## Part V: Counterfactual Reasoning

---
## Counterfactual Example 
- Joe is `\(60\)` years old, exercised `\(10\)` units, and has total cholesterol of `\(140\)`.
 - What would Joe's cholesterol be if he had exercised `\(20\)` units instead of `\(10\)`?

- Difference between causal inference and counterfactual reasoning

 - Average Causal Effect applies to populations
 - Counterfactual reasoning can answer questions about an individual

---
## Counterfactual Reasoning: Naive Approach
- Joe is `\(60\)` years old, exercised `\(10\)` units, and has total cholesterol of `\(140\)`.
 - What would Joe's cholesterol be if he had exercised `\(20\)` units instead of `\(10\)`?
 
- Use regression equation from observational data, with `\(A=60\)` and `\(E=20\)`:

$$
`\begin{align}
c &amp;= 99.91+-1.01e + 0.5a \\
 &amp;= 99.91+-1.01\cdot 20 + 0.5\cdot 60 \\
 &amp;= 109.71
\end{align}`
$$
- This is incorrect, because it ignores what we have learned about Joe by measuring what has already happened to him

 - This approach estimates `\(E(C|do(E=20), A=60)\)`
 - We need to estimate the expected value of Joe's cholesterol if he had exercised at `\(20\)` units, given the previously observed evidence regarding Joe:
`$$E(C_{E=20}|E=10, A=60, C=C_{E=10}=140)$$`

---
## Causal DAGs as Structural Equations
A causal DAG is a set of structural equations with endogenous and exogenous variables.

.pull-left[

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
e &lt;- 0.3*a + rnorm(n)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-74-1.png)&lt;!-- --&gt;
]

.pull-right[
$$
`\begin{align}
A &amp;= U_a \\
E &amp;= 0.3 A + U_e \\
C &amp;= 0.5 A + -1E + U_c
\end{align}`
$$

`\(U = \{U_a, U_e, U_c\}\)` is the set of exogenous variables
- Exogenous variables represent background conditions with no explantory mechanism encoded in the model

`\(V = \{A, E, C\}\)` is the set of endogenous variables

- The values of endogenous variables are defined through functions encoded in the model

Given a set of values for `\(U\)`, the model functions uniquely define the values of `\(V\)`, to determine the counterfactual:
`$$E(C_{E=20}|E=10, A=60, C=C_{E=10}=120)$$`
]

---
## What would Joe's Cholesterol Have been with E=20?
.pull-left[
**Step 1:** Use prior observations from Joe to determine Joe's background factors

Observed: `\(A = 60\)`, `\(E = 10\)`, `\(C = 140\)`

Substitute and solve:
$$
`\begin{align}
A = 60 &amp;= U_a \\
E = 10 &amp;= 0.3 \cdot 60 + U_e \\
C = 140 &amp;= 0.5 \cdot 60 + -1\cdot 10 + U_c \\
\\
U_a &amp;= 60 \\
U_e &amp;= -8 \\
U_c &amp;= 120
\end{align}`
$$
]

.pull-right[
**Step2:** Using the original model functions:

$$
`\begin{align}
A &amp;= U_a \\
E &amp;= 0.3 A + U_e \\
C &amp;= 0.5 A + -1E + U_c
\end{align}`
$$

Replace the function for `\(E\)` with `\(20\)`, substitute Joe's values for `\(U\)` and the remaining `\(V\)` values to determine the counterfactual

`$$E(C_{E=20}|E=10, A=60, C=C_{E=10}=140)$$`
$$
`\begin{align}
A &amp;= 60 \\
E &amp;= 20 \\
C_{E=20} &amp;= 0.5 \cdot 60 + -1\cdot 20 + 120 = 130
\end{align}`
$$
Naive version had `\(C = 109.71\)`
]
---
## Remaining slides are not part of the presentation

---
## Classic Definition of Confounder 
.pull-left[
A counfounder of `\(X\)` (the treatment) and `\(Y\)` (the outcome) is a variable `\(Z\)` that is

1. associated with `\(X\)`

2. is a cause of `\(Y\)`; and

3. does not reside on the causal pathway between `\(X\)` and `\(Y\)`
]
.pull-right[
Z is a confounder of `\(X \rightarrow Y\)`
![](overview_causal_inference_files/figure-html/unnamed-chunk-75-1.png)&lt;!-- --&gt;
]
???
This definition may be correct, though it is limited

reference for classical definition: Rothman KJ, Lash TL, Greenland S. Modern Epidemiology, 3rd ed. Philadelphia, PA: Lippincott Williams &amp; Wilkins; 2008. p. 195.

---


---
### Does Estrogen Replacement Therapy (ERT) Cause Uterine Cancer?
In the 1970's

- ERT widely prescribed to women after menopause
- Several studies found an association between ERT and uterine cancer
- ERT known to cause bleeding in some women
- Uterine cancer can cause bleeding

Two Hypotheses

- ERT causes uterine cancer
- ERT does not cause cancer, but causes bleeding, leading to a uterine exam, which increases the chance of finding undiagnosed uterine cancer

Yale researchers proposed limiting data analysis to women who have bled

Harvard researchers argued that such an analysis could find an association between ERT and Cancer even if ERT did not cause cancer

---
## Causal DAGs for each hypothesis
.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-76-1.png)&lt;!-- --&gt;
]
---
## Adjust done at data collection or analysis (from Elwert)

---
## Causal DAGs and Joint Probability Distributions
.pull-left[
Any distribution generated by a Markovian causal DAG `\(M\)`, can be written as:

`$$P(v_1,v_2,...,v_n) = \prod_{i} P(v_{i}|pa_i)$$`

where `\(V_1, V_2,..., V_n\)` are the variables in `\(M\)`, and `\(pa_i\)` are the values of the parents of `\(V_i\)` in M.
]

.pull-right[
![](overview_causal_inference_files/figure-html/unnamed-chunk-77-1.png)&lt;!-- --&gt;

`$$P(a,e,c)=P(a)*P(e|a)*P(c|a, e)$$`
]

For example, the probability that a patient has A=50, E = 5, and C = 120 is given by:

`$$P(A=50,E=5,C=120)=P(a=50)*P(e=5|a=50)*P(c=120|a=50, e=5)$$`


.whisper[Technical notes: A graph is Markovian if there are no cycles and all error terms jointly indpendent.]

---
##Formal Definitions
For treatment X and outcome Y...
### Causal Effect
Value of Y given a specific intervention on X

  - Dichotomous (binary) outcomes: `\(P(Y=1|do(X = x)\)`

  - Continuous outcomes:  `\(E(Y|do(X=x))\)`
  
---
# Overadjustment Bias

---
# In General, No single multivariable regression can identify multiple causal effects

---
# Causal Inference Requires extra-Data Information
- There is not enough information in the data to determine causal effects
- An analyst must use a causal model
- Conclusions are always relative to the model

---
#Observational Results: Age and Exercise(!) Increase Cholesterol

.pull-left[
### Cholesterol vs Age
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-79-1.png" width="70%" /&gt;
`\(c = 89.79+0.5a \space (p&lt;.001)\)` (obs and int dist identical)
]
.pull-right[
### Wrong: Cholesterol vs Exercise
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-80-1.png" width="70%" /&gt;
]

---
## Intervening Changes the Generative Model
.pull-left[
Dichotomous Observational Generative Model

```r
n &lt;- 10000
g &lt;- rbinom(n, 1, .5)
*p_x_g &lt;- c(1/3, 2/3)
*x &lt;- rbinom(n, 1, p_x_g[g]) # Male: 1/3, Female: 2/3 
# gender  treatment p(heart attack)
#  male       0           .3
#  male       1           .4
# female      0           .05
# female      1           .07
p_h_gx = c(.3, .4, .05, .075)
h &lt;- rbinom(n, 1, p_h_gx[g*2+x+1])
```
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-82-1.png" width="100%" /&gt;
]
.pull-right[
Dichotomous Interventional Generative Model

```r
n &lt;- 10000
g &lt;- rbinom(n, 1, .5) 
*x &lt;- rbinom(n, 1, .5) # Random chance
#          m¬t  mt  f¬t  ft
p_h_gx = c(.3, .4, .05, .075) # p(H|M,T)
h &lt;- rbinom(n, 1, p_h_gx[g*2+x+1])
```
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-84-1.png" width="100%" /&gt;

```r
# CPT of h given g and x
p_h = dint %&gt;% group_by(G, X) %&gt;% summarise(p_h = sum(H == 1)/n())
xtabs(p_h ~ G+X, p_h)
```

```
##    X
## G            0          1
##   0 0.29956297 0.40245837
##   1 0.04842615 0.07571486
```
]

---
P(h|g,x)

```r
# CPT of h given g and x, with marginals
p_h = dint %&gt;% group_by(G, X) %&gt;% summarise(p_h = sum(H == 1)/n())
addmargins(xtabs(p_h ~ G+X, p_h))
```

```
##      X
## G              0          1        Sum
##   0   0.29956297 0.40245837 0.70202134
##   1   0.04842615 0.07571486 0.12414101
##   Sum 0.34798912 0.47817323 0.82616235
```

---
## GGPlotly graph
<div id="htmlwidget-490946b3ff111244ac6f" style="width:100%;height:504px;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-490946b3ff111244ac6f">{"x":{"url":"overview_causal_inference_files/figure-html//widgets/widget_unnamed-chunk-87.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
