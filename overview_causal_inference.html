<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>A Brief Overview of Causal Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Todd R. Johnson, PhD   Professor      tjohnson250     @johnsontoddr4    todd.r.johnson@uth.tmc.edu" />
    <meta name="date" content="2019-06-29" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/jquery/jquery.min.js"></script>
    <link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding/datatables.js"></script>
    <link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <script src="libs/viz/viz.js"></script>
    <link href="libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="libs/grViz-binding/grViz.js"></script>
    <script src="libs/pymjs/pym.v1.js"></script>
    <script src="libs/widgetframe-binding/widgetframe.js"></script>
    <script src="https://kit.fontawesome.com/08ea13597f.js"></script>
    <link rel="stylesheet" href="my-fonts.css" type="text/css" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# A Brief Overview of Causal Inference
### Todd R. Johnson, PhD <br> Professor <br><br> <a href="https://github.com/tjohnson250"><i class="fab fa-github fa-fw"></i>  tjohnson250</a><br> <a href="https://twitter.com/johnsontoddr4"> <i class="fab fa-twitter fa-fw"></i>  <span class="citation">@johnsontoddr4</span></a><br> <a href="mailto:todd.r.johnson@uth.tmc.edu"><i class="fa fa-paper-plane fa-fw"></i>  todd.r.johnson@uth.tmc.edu</a><br><br>
### The University of Texas School of Biomedical Informatics at Houston
### 2019-06-29

---




# Disclaimer

Use the arrow keys to navigate. Press .key[h] `h` for help. To see speaker notes, press `p` to enter presentation mode. 

This is unfinished work. My primary objective for creating this presentation is to help me understand the basics of causal infererence. I hope to use it to help others as well, especially machine learning researchers who tend to make predictive, rather than causal models.

This presentation is hosted on Github Pages at: https://tjohnson250.github.io/overview_causal_infererence/overview_causal_infererence.html#1

The source code to generate the presentation is at: https://github.com/tjohnson250/overview_causal_infererence

If you find errors or have suggestions for improvement, open an issue on this project's Github repo.

---
# Pearl's Three Layer Causal Hierarchy

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Level &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Typical.Activity &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Typical.Questions &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Examples &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 1. Association&lt;br&gt;\(\mathbf{P(y|x)}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Seeing &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; What is?&lt;br&gt;How would seeing X change my belief in Y? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; What does a symptom tell me about a disease?&lt;br&gt;What does a survey tell us about the election results? &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 2. Intervention&lt;br&gt;\(\mathbf{P(y|do(x), z)}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Doing,&lt;br&gt;Intervening &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; What if?&lt;br&gt;What if I do X? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; What if I take aspirin, will my headache be cured?&lt;br&gt;What if we ban cigarettes? &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: #1c5253 !important;"&gt; 3. Counterfactuals&lt;br&gt;\(\mathbf{P(y_x|x',y')}\) &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Imagining,&lt;br&gt;Retrospecting &lt;/td&gt;
   &lt;td style="text-align:left;width: 8em; "&gt; Why?&lt;br&gt;Was it X that caused Y?&lt;br&gt;What if I had acted differently? &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Was it the aspirin that stopped my headache?&lt;br&gt;Would Kennedy be alive had Oswald not shot him?&lt;br&gt;What if I had not been smoking the past 2 years? &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
class: middle

### Part I: Causation

### Part II: Identifying and Estimating Causal Effects from Observational Data

### Part III: Causal Model Evaluation

### Part IV: Causal Discovery from Observational Data

### Part V: Counterfactual Reasoning

---
class: center, middle

# Part I: Causation

---

# Definitions

**Causal Infererence** is the process of inferring the **causal effect** of one random variable on a second random variable.

The **Causal Effect** of `\(X\)` on `\(Y\)` is the change in `\(Y\)` when we **intervene** and directly change `\(X\)` from one value to another.

**Intervening** on `\(X\)` means to force `\(X\)` to take a specific value, independent of any of the variables that normally influence the value of `\(X\)`

 - Suppose that the decision to treat is normally influenced only by gender, *intervening* means ignoring gender when deciding on treatment, such as by randomly assigning whether to treat or not  
  
 - This is why RCTs are considered the gold standard for identifying causal effects

---
# Example: Age, Exercise and Cholesterol
Suppose that the following model accurately describes how age, exercise, and cholesterol are related

.pull-left[

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
e &lt;- 0.3*a + rnorm(n)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
]

.pull-right[
From the model, the causal effect of exercise on cholesterol is `\(-1e\)`:

  - For every unit increase in excercise, cholesterol decreases by `\(1\)`
  
Causal DAG (Directed Acyclic Graph)
  - Graphical representation of the data generating model
  - Links represent *possible* direct causal effects
  - Missing links indicate the strong assumption of no direct causal effect
  - Must include all common causes of any pair of variables already in the DAG
]

---
exclude: true
# Lavaan exploration

```r
library(lavaan)
model &lt;- '
  # regressions
  A ~ 1
  E ~ A
  C ~ A + E
  '
fit &lt;- sem(model, data=dobs)
summary(fit, standardized=TRUE)
```

```
## lavaan 0.6-4.1415 ended normally after 34 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                          9
## 
##   Number of observations                         10000
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                       0.000
##   Degrees of freedom                                 0
##   Minimum Function Value               0.0000000000000
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                             Standard
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   E ~                                                                   
##     A                 0.301    0.001  298.226    0.000    0.301    0.948
##   C ~                                                                   
##     A                 0.494    0.016   31.090    0.000    0.494    0.893
##     E                -0.965    0.050  -19.287    0.000   -0.965   -0.554
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##     A                49.951    0.100  498.839    0.000   49.951    4.988
##    .E                -0.048    0.051   -0.928    0.353   -0.048   -0.015
##    .C                99.871    0.257  388.315    0.000   99.871   18.040
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .E                 1.020    0.014   70.711    0.000    1.020    0.101
##    .C                25.553    0.361   70.711    0.000   25.553    0.834
##     A               100.269    1.418   70.711    0.000  100.269    1.000
```

---
## Intervening Changes the Generative Model
Intervene by randomly setting `\(E\)` from `\(0 - 20\)`
.pull-left[
### Observational Model

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
*e &lt;- 0.3*a + rnorm(n)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
]

.pull-right[
### Interventional Model

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
*e &lt;- sample(0:20, n, replace = TRUE)
c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;
]

---
## Intervening Changes The Distribution

.pull-left[
### Observational Distribution
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-7-1.png" width="70%" /&gt;

`\(c = 102.43+0.51e \space (p&lt;.001)\)`
]

--

.pull-right[
### Interventional Distribution
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-8-1.png" width="70%" /&gt;

`\(c = 124.95+-1e \space (p&lt;.001)\)`
]

???
The coefficient for `\(e\)` on the observational distribution is way off, but the coefficient for the interventional distribution is close. Both coefficents are statistically significant at the p = .001 level.

---
# Difference Between Seeing and Doing
.pull-left[
### Observational Association
`\(E(C|e)\)`: The expected value of Cholesterol given that we observe a specific level of exercise.

`\(E(C|e)\)` is confounded, because age `\(A\)` affects both the amount of exercise `\(E\)` a person gets and cholesterol levels `\(C\)`.
]
.pull-right[
### Interventional Association (Causal Effect)
`\(E(C|do(e))\)`: The expected value of Cholesterol given that we intervene and set exercise to a specific value, independent of any of the variables that normally influence the value of `\(E\)`.

`\(do()\)` is called the do-operator.
]

---
### Average Causal Effect (ACE) for a Population
Contrast of the mean values of `\(Y\)` (outcome) given two specific interventions on `\(X\)` (treatment)

- Dichotomous (binary) outcomes: 

    `$$P(Y=1|do(X = 1)-P(Y=1|do(X = 0)))$$`
    
    `$$P(Survival|do(Treat))-P(Survival|do(Don't Treat))$$`

- Continuous outcomes:  

    `$$E(Y|do(X=x)) - E(Y|do(X=x^{\prime})$$`

First equation is a special case, since for dichotomous outcomes 
  `$$E(Y|do(X=x)) = P(Y=1|do(X = x))$$`
???
ACE is also called the Average Treatment Effect (ATE)

Contrast ACE with the individual causal effect: the difference between counterfactual outcomes for a single patient--the outcome if treated vs. the outcome if not treated. Lack of an average causal effect does not imply lack of an individual causal effect. However, in most cases it is impossible to estimate individual causal effects from observational data because we only ever observe the effect of one level of the treatment for an individual. 

A crossover randomized experiment in which we give different treatments over time to the same person can sometimes measure individual causal effects when treatment and outcome are short term and do not affect the next treatment period. This is commonly used in cognitive science  and psychology in within-subject designs. For example, we might measure a subject's ability to monitor different numbers of patients using a telemonitoring system to determine the effect of patient load on time to respond to events, error rate, etc.

See Hernan and Robbins, Causal Inference, Chapter 1 and Fine Point 2.1 for more details in individual vs. population causal effects. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/

---
## Estimating ACE of Exercise on Cholesterol Using the Interventional Dataset
Step 1: Estimate functional relationship between C and E using linear regression on the **interventional dataset**:



`$$c = 124.95+-1e \space (p&lt;.001)$$`

`$$E(C|do(E=e))=124.95+-1e \space (p&lt;.001)$$`

Step 2: Use regression equation to calculate ACE

$$
`\begin{align}
  ACE &amp;= E(Y|do(E=1))-E(Y|do(E=2)) \\
      &amp;= (124.95+-1*1) - (124.95+-1*2) \\
      &amp;= 122.95 - 123.95 \\
      &amp;= -1
\end{align}`
$$
Equivalently: The regression coefficent on `\(e\)` directly tells us how much `\(C\)` will change for each unit increase in `\(E\)`.

---
class: center, middle, Large

We say that `\(\mathbf{X}\)` **causes** `\(\mathbf{Y}\)` in a population when the **average causal effect** of `\(X\)` on `\(Y\)` is non-zero.

---
class: center, middle

## Part II: Identifying and Estimating Causal Effects from
## Observational Data

---
## With Observational Data...
.pull-left[
#### using E to predict C gives an incorrect estimate,
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-10-1.png" width="70%" /&gt;

`\(c = 102.43+0.51e \space (p&lt;.001)\)`
]

--

.pull-right[
#### but controlling for C gives the correct estimate
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-11-1.png" width="70%" /&gt;

`\(c = 99.87+-0.97e + 0.49a \space (p&lt;.001)\)`
]
???
The graph on the right shows the observational data with a regression line for each of several age groups. As you can see, most of the lines show the appropriate negative correlation between `\(C\)` and `\(E\)`. Lines near the left and right are incorrect due to sparse data. Stratifying by age (here age group) is one method for controlling or adjusting for a confounder, such as `\(A\)`.

The regression equation also shows a very close estimate of the correct causal effect of `\(E\)` on `\(C\)`. Regressing `\(C\)` on both `\(E\)` and `\(A\)` controls or adjusts for `\(A\)`, returning the close estimate of the true causal effect of `\(E\)` on `\(C\)`.

---
## Adjustment
Stratifying by age `\((A)\)` or including `\(A\)` as a covariate in the regression `\((C = {\beta_1}+{\beta_2}A + {\beta_3}E)\)` is called **adjusting**, **conditioning**, or **controlling for A**

In R code, regression using the observational dataset (`dobs`):
.pull-left[
Unadjusted for `\(A\)`

```r
lm(C ~ E, dobs)
```

```
## 
## Call:
## lm(formula = C ~ E, data = dobs)
## 
## Coefficients:
## (Intercept)            E  
##    102.4338       0.5099
```
]
.pull-right[
Adjusted for `\(A\)`

```r
lm(C ~ E + A, dobs)
```

```
## 
## Call:
## lm(formula = C ~ E + A, data = dobs)
## 
## Coefficients:
## (Intercept)            E            A  
##     99.8711      -0.9652       0.4937
```
]
---
### What is the Causal Effect of Age on Cholesterol?
Using the observational dataset, regressing `\(C\)` on `\(A\)` and `\(E\)` gave us: `\(c = 99.87+-0.97e + 0.49a\)`
.pull-left[

```r
n &lt;- 10000
a &lt;- rnorm(n, mean = 50, sd = 10)
e &lt;- 0.3*a + rnorm(n)
*c &lt;- 0.5*a + -1*e + rnorm(n, mean = 100, sd = 5)
```
![](overview_causal_inference_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;
]
.pull-right[
From the model, the **direct causal effect** of `\(A\)` on `\(C\)` is `\(0.5a\)`

  - Regressing `\(C\)` on `\(A\)` and `\(E\)` closely estimates this effect.

  - However `\(A\)` also affects `\(C\)` through `\(E\)`

The **total causal effect** of `\(A\)` on `\(C\)` includes the effect of `\(A\)` through both paths,  which from the model is:

$$
`\begin{align}
  c &amp;= .5a + -1\mathbf{e} \\
    &amp;= 0.5a + -1\mathbf{(0.3a)} \\
      &amp;= 0.5a\mathbf{- 0.3a} \\
      &amp;= 0.2a \\
\end{align}`
$$

]

---
### A Single Analysis is Usually Insuffient to Measure All Effects
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-16-1.png" width="70%" /&gt;

`\(c = 99.92+0.2a \space (p&lt;.001)\)`
]
.pull-right[
This simple 3 variable dataset requires two different regression analyses to estimate the causal effects of `\(A\)` on `\(C\)` and `\(E\)` on `\(C\)`
  
- Total effect of `\(E\)`, Direct effect of `\(A\)`:

    `\(c = 99.87+-0.97e + 0.49a \space (p&lt;.001)\)`

-  Total effect of `\(A\)`:

    `\(c = 99.92+0.2a \space (p&lt;.001)\)`
  
Simply throwing all covariates into a single regression is insufficient... but this is what most machine learning models do
]
???
To get the direct effect of `\(A\)` and `\(E\)` (thereby estimating all path coefficients) we would have to regress `\(E\)` on `\(A\)`. Later slides show that we don't need to adjust for `\(C\)` because it is a collider. Adjusting for `\(C\)` would give an incorrect estimate of the effect of `\(A\)` on `\(E\)`.

---
class: center, middle

.Large[How do we know when and what to adjust for?]

---
## Paths in Causal DAGs
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-17-1.png" width="70%" /&gt;
]
.pull-right[
A **path** is a sequence of non-intersecting adjacent edges
  - Non-intersecting means a path cannot cross a node more than once
  - Direction of the arrows doesn't matter

Examples:
  - `\(A \rightarrow E\)`
  - `\(A \rightarrow E \rightarrow C\)`
  - `\(E \leftarrow A \rightarrow C\)`
  
All associations are transmitted along paths,
but not all paths transmit association!
]

???
Source: https://www.ssc.wisc.edu/~felwert/causality/wp-content/uploads/2013/06/2-elwert_dags.pdf
See here for how to cite sources using refmanager package: https://github.com/yihui/xaringan/wiki/Bibliography-and-citations

---
class: center, middle
.Large[Two Kinds of Paths: **Causal** and **Non-Causal**]

---
## Causal Paths
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-18-1.png" width="70%" /&gt;
]
.pull-right[
**Causal Path:** A path in which all arrows point away from the treatment to the outcome
 - Causal path for Treatment `\(E\)` and Outcome `\(C\)`
    * `\(E \rightarrow C\)`
  
 - Causal paths for Treatment `\(A\)` and Outcome `\(C\)`
    * `\(A \rightarrow E \rightarrow C\)`
    * `\(A \rightarrow C\)`
    
The **total causal effect** of a treatment on an outcome consists of association transmitted along all causal paths connecting them
]

---
## Non-Causal Paths
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-19-1.png" width="70%" /&gt;
]
.pull-right[
**Non-Causal Path:** A path from the treatment to the outcome in which at least one arrow points back to the treatment
 - Non-Causal path for Treatment E and Outcome C
    * `\(E \leftarrow A \rightarrow C\)`
  
 - Non-Causal paths for Treatment `\(A\)` and Outcome C
    * None
    
Non-causal paths are potential spurious sources of association between treatment and outcome
]

---
### Causal and Non-Causal Paths for Treatment E and Outcome C
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-20-1.png" width="70%" /&gt;
]
.pull-right[
Causal path:
  - `\(E \rightarrow C\)`
  
Non-Causal path:
  - `\(E \leftarrow A \rightarrow C\)`

    
The non-causal path is a source of confounding because it transmits spurious association between `\(E\)` and `\(C\)`

Adjusting for `\(A\)` in the observational data blocks this path, allowing us to use the observational data to estimate the causal effect of `\(E\)` on `\(C\)`
]

---
## Identifiability
A causal effect is **identifiable** if the controlled (post-intervention) distribution can be estimated from data drawn from the observational (pre-intervention) distribution.

The **Backdoor Criterion** is one identification method:

The causal effect of `\(T\)` on `\(Y\)` is **identifiable** if
we can adjust for a set of variables that

 - blocks all non-causal paths between `\(T\)` and `\(Y\)`
 - without blocking any causal paths between `\(T\)` and `\(Y\)`

---
### Blocking and Unblocking Paths
All Causal DAGs are a combination of these three patterns:

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-21-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-22-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-23-1.png" width="70%" /&gt;
]
.pull-right[
**Linear Path (or Chain)**

  - Adjusting for `\(E\)` (a mediator) *blocks* the path between `\(A\)` and `\(C\)`

**Common Cause**

  - Adjusting for `\(A\)` *blocks* the path between `\(E\)` and `\(C\)`

`$$\space$$`

**Common Effect**

  - `\(C\)` is called a collider
  - Unadjusted colliders *block* the path
  - Adjusting for `\(C\)` (or a descendent of `\(C\)`)  **unblocks or opens** the path
]

---
## Identifying the Total Effect of `\(A\)` on `\(C\)`
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-24-1.png" width="70%" /&gt;
]
.pull-right[
**Total Effect of `\(A\)` on `\(C\)`**

No adjustments needed

  - All paths from `\(A\)` to `\(C\)` are causal

  * `\(A \rightarrow C\)`
  * `\(A \rightarrow E \rightarrow C\)`

**Direct Effect of `\(A\)` on `\(C\)`**

Adjusting for `\(E\)` blocks the path `\(A \rightarrow E \rightarrow C\)` leaving only the direct path `\(A \rightarrow C\)`
]

---
## Identifying the Total Effect of `\(A\)` on `\(E\)`
.pull-left[
Observational Causal DAG
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-25-1.png" width="70%" /&gt;
]
.pull-right[
**Total (and Direct) Effect of `\(A\)` on `\(E\)`**

No adjustments needed

  * Causal path

    - `\(A \rightarrow E\)`

  * Non-causal path, blocked by collider `\(C\)`
  
    - `\(A \rightarrow C \leftarrow  E\)`
    
    - Adjusting for `\(C\)` would distort the effect estimate
]

---
## Backdoor Criterion (Pearl 1995)
A set of variables `\(\{Z\}\)` (possibly empty) satisfies the **backdoor criterion** relative to an ordered pair of variables `\(\{X, Y\}\)` in a DAG if:

  1. no node in `\(\{Z\}\)` is a descendent of `\(X\)`, and
  
  2. `\(\{Z\}\)` blocks every path between `\(X\)` and `\(Y\)` that contain an arrow into `\(X\)` (the "backdoor paths")
  
If `\(\{Z\}\)` meets the backdoor criterion, the total causal effect of `\(X\)` on `\(Y\)` is non-parametrically identifiable given `\(\{Z\}\)`, such that:

$$ P(Y|do(X)) = \sum_{Z} P(Y|X,Z)P(Z)$$

The backdoor criterion recognizes that all paths that descend from `\(X\)` are either causal or blocked
---

## Multiple Adjustment Sets
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-26-1.png" width="70%" /&gt;
]
.pull-right[
Adjustment sets for `\(X \rightarrow Y\)`:


```
##  { W1, W2, Z2 }
##  { V, W1, W2 }
##  { W1, W2, Z1 }
```

Adjusting for any one of these sets of variables eliminates confouding for the causal effect of `\(X\)` on `\(Y\)`

For a linear model this means regressing `\(Y\)` on `\(X\)`, including as covariates only one set of these variables 

In R, any of these statements will estimate the total effect of `\(X\)` on `\(Y\)` from observational data `obsdata`:


```r
lm(obsdata, Y ~ X + W1 + W2 + Z2)
lm(obsdata, Y ~ X + V + W1 + W2)
lm(obsdata, Y ~ X + W1 + W2 + Z1)
```
]

---
# Adjustment Sets for `\(X \rightarrow Y\)`

![](overview_causal_inference_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;
???
Bold edges are unadjusted, light edges are adjusted

The backdoor criterion implicitly prevents adjusting for children of mediators. For instance, suppose we want to determine the causal effect of `\(X\)` on `\(Y\)` in the model:

`$$X \rightarrow Z \rightarrow Y$$`
`$$Z \rightarrow Z_2$$`
where `\(Z\)`, a mediator, causes `\(Z_2\)`. It is clear that adjusting for `\(Z\)` would block the path between `\(X\)` and `\(Y\)`, but adjusting for `\(Z_2\)` would partially block the path.

---
# Frontdoor Adjustment Criterion
.pull-left[
U unmeasured: Cannot block backdoor path from `\(X \rightarrow Y\)`

&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-30-1.png" width="70%" /&gt;
]
.pull-right[
`\(X \rightarrow Y\)` is still identifiable using a two step process:

Step 1. Identify `\(X \rightarrow Z\)`:

  * Backdoor path blocked by collider `\(Y\)`
  
`$$X \leftarrow U \rightarrow Y \leftarrow Z$$`
  * In R: `lm(obsdata, Z ~ X)`
  
Step 2. Identify `\(Z \rightarrow Y\)`:

  * Backdoor path blocked by adjusting for `\(X\)`

`$$Z \leftarrow X \leftarrow U \rightarrow Y$$`
  * In R: `lm(obsdata, Y ~ Z + X)`
]
???
Since `\(U\)` is unmeasured, we cannot adjust for it. However, in this case, the frontdoor adjustment criterion allows us to identify the causal effect of `\(X\)` on `\(Y\)` in two steps.
---
## Frontdoor Adjustment Criterion (Pearl 1995)
A set of variables `\(\{Z\}\)` satisfies the **frontdoor criterion** relative to an ordered pair of variables `\(\{X, Y\}\)` in a DAG if:

  1. `\(\{Z\}\)` intercepts all directed paths from `\(X\)` to `\(Y\)`,
  
  2. there is no backdoor path between `\(X\)` and `\(Z\)`,
  
  3. every backdoor path between `\(Z\)` and `\(Y\)` is blocked by `\(X\)`
  
If `\(\{Z\}\)` meets the frontdoor criterion, the causal effect of `\(X\)` on `\(Y\)` is identifiable given `\(\{Z\}\)`, such that:

`$$P(y|do(x)) = \sum_{z} P(z|x)\sum_{x'}P(y|x', z)P(x')$$`

`\(x\)` is the value of `\(X\)` in `\(do(x)\)`, `\(x'\)` refers to all values of `\(X\)`

---
## Instrumental Variables
Instrumental variables are those that only affect the treatment, with no relationship to anything else

---
# Identifying Covariate Specific Effects
Suppose a drug `\(D\)` affects `\(C\)`, gender `\(G\)` affects who takes the drug.

.pull-left[
What is the effect of `\(E\)` on `\(C\)` when we *observe* `\(D = d\)`?
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-31-1.png" width="70%" /&gt;
]
.pull-right[
Estimate `\(P(C=c|do(E=e), D=d)\)`


Must use an adjustment set `\({S} \cup D\)` that blocks all backdoor paths from `\(E\)` to `\(C\)`.

No need to block backdoor path from `\(D\)` to `\(C\)`.

Valid adjustment set: `\({A, D}\)`

Regression: `lm(obsdata, C ~ A + D)`

Mathematically:

`$$\begin{aligned} P(Y=y&amp;|do(X=x), Z=z) = \\  &amp;\sum_S P(Y=y|X=x, S=s, Z=z)P(S=s|Z=z) \end{aligned}$$`

]
???
Note that the summation in the adjustment formula is over `\(S\)`, not `\(S \cup Z\)`. `\(S\)` is the set of all the other variables needed to block the backdoor paths from `\(X\)` to `\(Y\)`.

We don't want to block the backdoor path from `\(D\)` to `\(C\)` here, because the query is asking for the effect of `\(E\)` on `\(C\)` when we intervene on `\(E\)` and then in the resulting interventional distribution observe `\(D=d\)`.

In contrast, if we just want to identify `\(P(Y=y|do(X=x))\)` we have:

`$$P(Y=y|do(X=x)) = P(Y=y|X=x, S=s)P(S=s)$$`

where `\(S\)` is a valid adjustment set that blocks the backdoor paths from `\(X\)` to `\(Y\)`.

The basic idea is that when we look at the interventional distribution (resulting from adjusting for `\(S\)`), we must stratify by `\(Z\)` to compute the covariate-specific effect, which means we are also adjusting for `\(Z\)`. Thus we have to make sure that adjusting for `\(Z\)` does not open any backdoor paths for the effect from `\(X\)` to `\(Y\)`.]

---
### Identifying the Effects of Multiple Interventions
What is the effect of simultaneously intervening on `\(X\)` and `\(Z2\)`?
.pull-left[
What is the effect of `\(E\)` on `\(C\)` when we *observe* `\(D = d\)`?
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-32-1.png" width="70%" /&gt;
]
.pull-right[
Estimate `\(P(C=c|do(E=e, D=d))\)`

Must use an adjustment set that blocks all backdoor paths from `\(E\)` to `\(C\)` and `\(D\)` to `\(C\)`


```
##  { A, G }
```
Regression: `lm(C ~ E + A + D + G)`

Mathematically:

`$$\begin{aligned} P(Y=y&amp;|do(X=x, Z=z)) = \\  &amp;\sum_S P(Y=y|X=x, Z=z, S=s)P(S=s) \end{aligned}$$`
]
???
To estimate the effect of simultaneously intervening on `\(X\)` and `\(Z2\)`, we need an adjustment set that blocks all backdoor paths for both variables.

In this case the regression must include `\(X\)` and `\(Z2\)`:

```r
lm(Y ~ X + W1 + W2 + Z2)
```

Here, we can use the same regression equation as the previous covariate-specific example. But consider `\(P(y|do(x,w1))\)` vs. `\(P(y|do(x), w1)\)`.

The adjustment set for `\(P(y|do(w1,z1))\)` is:

```
##  { W1 }
```
The regression is:

```r
lm(Y ~ W1 + Z1 + V)
```
The adjustment sets for `\(P(y|do(w1), z1)\)` are:

```
##  {}
```

---
## Confounding is a Causal Concept

* The data alone are insufficient to identify confounders or control for confouding
* Without a causal model, observational data is limited to associational models that do not tell us how to intervene
  + This includes all common machine learning and statistical approaches
  + Example: If an associational predictive model finds a few highly predictive "risk factors" we cannot assume that intervening on those risk factors will decrease risk.
  + Variables that increase the predictive power of an associational model may include effects of the outcome, such as symptoms of a disease you are trying to predict
* Associational predictive models are still useful if we already have interventions that are known to work
  + If we know that a treatment works if given earlier in the course of a disease, better predictive models can tell us who to treat

---
class: center, middle, Large

Causal Inference Requires a Causal Model,

But...

How Do we Know if Our Model is Correct?
---
class: center, middle
# Part III: Model Evaluation

---
# Two Approaches to Model Evaluation
Local fit tests

- Tests of model-implied conditional independence assumptions

Global fit tests

- Model chi-square: comparison of model vs. observed covariance matrices)

- RMSEA: Root Mean Square Error of Approximation

- CFI: Comparative fit index

- SRMSR: Standaridzed Root Mean Square Residual
???
From: Kline RB. Principles and practice of structural equation modeling. Guilford publications; 2015 Nov 3.
---
## Model Evaluation
Causal DAG's imply independence relations

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-38-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-39-1.png" width="70%" /&gt;
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-40-1.png" width="70%" /&gt;
]
.pull-right[
**Linear Path (or Chain)**

  - `\(A \perp\!\!\!\perp C | E\)`



**Common Cause**

  - `\(E  \perp\!\!\!\perp  C | A\)`

`$$\space$$`
`$$\space$$`

**Common Effect**

  - `\(A  \perp\!\!\!\perp  E\)`
  - `\(A  \not\!\perp\!\!\!\perp  E | C\)`
]

---
## Example: Independence Relations
.small[Causal DAG Implied by Gostynski M, Gutzwiller F, Kuulasmaa K, Döring A, Ferrario M, Grafnetter D, Pajak A. **Analysis of the relationship between total cholesterol, age, body mass index among males and females in the WHO MONICA Project.** *International Journal of Obesity.* 2004 Aug;28(8):1082.]

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-41-1.png" width="70%" /&gt;
]

.pull-right[
This Causal DAG implies the following conditional independencies

.scroll-box-8[

```
bmigrp _||_ eageg | height, weight
bmigrp _||_ sex | height, weight
eageg _||_ height
eageg _||_ sex
height _||_ hychol | bmigrp, eageg, sex
hychol _||_ weight | bmigrp, eageg, sex
```
]

Given data on these variables, we can test for these statistical relationships.
]

---
### Model Evaluation by Testing Implied Independencies with Observed Data

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-43-1.png" width="70%" /&gt;
]

.pull-right[
Independence Tests for all implied independencies based on 17440 patients.


<div id="htmlwidget-b0d2ebacaa292a82da4b" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b0d2ebacaa292a82da4b">{"x":{"filter":"none","fillContainer":false,"data":[["bmigrp _||_ eageg | height, weight","bmigrp _||_ sex | height, weight","eageg _||_ height","eageg _||_ sex","height _||_ hychol | bmigrp, eageg, sex","hychol _||_ weight | bmigrp, eageg, sex"],[0.0130031546385232,-0.017136283212477,-2.19489596560299,-2.672352570735e-05,-0.00138660727127573,0.00100917415354059],[2.13804203310127e-06,0.0585862658646039,4.1824828237127e-142,0.998672916422782,0.458122403906288,0.0585862658646039]],"container":"<table class=\"nowrap hover\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":3,"dom":"tp","order":[[2,"asc"]],"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"autoWidth":false,"orderClasses":false,"lengthMenu":[3,10,25,50,100],"rowCallback":"function(row, data) {\nDTWidget.formatRound(this, row, data, 1, 2, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 2, 2, 3, ',', '.');\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
]

???
The table is sorted in increasing order by `p.values`

`p.values` were corrected for multiple comparisons using the Holm-Bonferroni method

Estimate should be close to `\(0\)` for tests with `\(p\)` less than a small threshold (here `\(.05\)`)

See Figure 1 in http://johannes-textor.name/papers/2017-ije.pdf for details (Textor J, van der Zander B, Gilthorpe MS, Liśkiewicz M, Ellison GT. Robust causal inference using directed acyclic graphs: the R package ‘dagitty’. *International journal of epidemiology.* 2016 Dec 1;45(6):1887-94.)

Tests for independence are linear in the dagitty package. Distance Correlation can detect non-linear independence For example:


```r
library(energy) # provides test for marginal independence using distance correlation 

# Tests show probability of independence
# Low p values indicate dependence

#  Distance correlation is computationally intensive $O(n^2)$ and memory intensive, so use a random sample of data
monicasamp &lt;- sample_n(monica, 1000)
dcor.ttest(monica$eage, monica$sex) # marginally independent

# Independence under partial correlation (whether distance or linear) is not identical to conditional independence. 
# The CDCSIS package (below) tests for conditional independence using distance correlation, whereas the energy package (above) only tests for partial distance correlation. 
# If all variables are multivariate gaussian, the partial linear correlation is 0 if and only if  X and Y are conditionally linearly independent given Z, but otherwise this is not true. 
# See the following paper for more details on the relationship between conditional independence of partial correlation: https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2004.00360.x

# See section 4.3 of (http://real.mtak.hu/44934/1/pdcov.pdf) Székely GJ, Rizzo ML. Partial distance correlation with methods for dissimilarities. The Annals of Statistics. 2014;42(6):2382-412.

# Test independence under partial correlation independence hypothesis using distance correlation. 
pdcor.test(monicasamp$bmigrp, monicasamp$weight, monicasamp$bmi, R=99) # Dependent although model implies independence

library(cdcsis) # Provides cdcsis and cdcsis.test for conditional distance correlation

# compute conditional distance correlation 
cdcsis(as.matrix(monicasamp$bmigrp), monicasamp$weight, as.matrix(monicasamp$bmi), threshold = 1) # must give threshold here as 1 for this data
# Test conditional independence hypothesis using distance correlation
cdcov.test(as.matrix(monicasamp$bmigrp), monicasamp$weight, as.matrix(monicasamp$bmi)) # Dependent at the .05 level, but not .01
```

---
# Coefficients where `\(p &lt; .05\)`

.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-46-1.png)&lt;!-- --&gt;
]

.pull-right[
The data suggests that `\(eage\)` and `\(height\)` are *not* marginally independent

This contradicts our model
]
---
## Add `\(eage \rightarrow height\)` and Retest

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-47-1.png" width="70%" /&gt;
]

.pull-right[
Coefficients where `\(p &lt; .05\)`

![](overview_causal_inference_files/figure-html/unnamed-chunk-48-1.png)&lt;!-- --&gt;
]

---
## Compare Model's Implied Covariance Matrix to Data

`\(p = 0\)` indicates that the covariance matrices are not similar.


.scroll-box-8[

```
lavaan 0.6-4.1415 ended normally after 24 iterations

  Optimization method                           NLMINB
  Number of free parameters                         18

  Number of observations                         17440

  Estimator                                       DWLS      Robust
  Model Fit Test Statistic                      19.265     151.984
  Degrees of freedom                                 3           3
  P-value (Chi-square)                           0.000       0.000
  Scaling correction factor                                  0.127
  Shift parameter                                            0.033
    for simple second-order correction (Mplus variant)

Model test baseline model:

  Minimum Function Test Statistic            34299.840   27768.575
  Degrees of freedom                                 6           6
  P-value                                        0.000       0.000

User model versus baseline model:

  Comparative Fit Index (CFI)                    1.000       0.995
  Tucker-Lewis Index (TLI)                       0.999       0.989

  Robust Comparative Fit Index (CFI)                            NA
  Robust Tucker-Lewis Index (TLI)                               NA

Root Mean Square Error of Approximation:

  RMSEA                                          0.018       0.053
  90 Percent Confidence Interval          0.011  0.026       0.046  0.061
  P-value RMSEA &lt;= 0.05                          1.000       0.210

  Robust RMSEA                                                  NA
  90 Percent Confidence Interval                                NA     NA

Standardized Root Mean Square Residual:

  SRMR                                           0.018       0.018

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model        Unstructured
  Standard Errors                           Robust.sem

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  height ~                                            
    eageg            -0.194    0.006  -35.175    0.000
    sex              -0.665    0.005 -121.151    0.000
  weight ~                                            
    height            0.472    0.007   63.437    0.000
    eageg             0.217    0.007   31.150    0.000
    sex              -0.094    0.009  -11.005    0.000
  bmigrp ~                                            
    weight            1.173    0.005  227.193    0.000
    height           -0.682    0.005 -126.544    0.000
  hychol ~                                            
    bmigrp            0.059    0.023    2.592    0.010
    weight            0.037    0.025    1.516    0.130
    sex               0.005    0.014    0.356    0.722
    eageg             0.300    0.011   26.323    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .height           -0.000    0.005   -0.000    1.000
   .weight           -0.000    0.007   -0.000    1.000
   .bmigrp            0.000                           
   .hychol            0.000                           

Thresholds:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    bmigrp|t1        -0.136    0.006  -22.315    0.000
    bmigrp|t2         1.015    0.010  106.699    0.000
    hychol|t1         0.618    0.010   59.275    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .height            0.519    0.005  114.581    0.000
   .weight            0.706    0.006  115.552    0.000
   .bmigrp            0.020                           
   .hychol            0.992                           

Scales y*:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    bmigrp            1.000                           
    hychol            1.000                           
```
]
???
For this test to show statistical equality between the implied covariance matrix of the model and the covariance matrix of the data, the Model Fit Test Statistic should be less than the degrees of freedom with a high `\(p\)`

---
## Visualize Mismatch between Model and Data Covariance Matrix
This shows observed - model-implied correlations
![](overview_causal_inference_files/figure-html/unnamed-chunk-51-1.png)&lt;!-- --&gt;
---
## Examine Modification Indices
MI Indicates possible improvement in model test score

```
##       lhs  op    rhs         mi      epc  sepc.lv sepc.all sepc.nox
## 17 bmigrp  ~~ bmigrp     32.184    1.628    0.020    0.019    0.019
## 22 bmigrp ~*~ bmigrp  54043.674 1662.387 1662.387    1.000    1.000
## 32 height  ~~ hychol   9591.984  -29.169  -29.169  -40.668  -40.668
## 34 weight  ~~ hychol 267436.747  444.013  444.013  530.581  530.581
## 35 bmigrp  ~~ hychol     32.184    0.096    0.096    0.679    0.679
## 38 height   ~ hychol   9601.754  -29.422  -29.422  -30.922  -30.922
## 39 weight   ~ bmigrp  30541.154  340.592  340.592  353.071  353.071
## 40 weight   ~ hychol 274777.281  453.735  453.735  475.681  475.681
## 41 bmigrp   ~ hychol     38.677    0.100    0.100    0.101    0.101
## 44 hychol   ~ height   9591.999  -56.246  -56.246  -53.517  -53.517
```
---
## Age, Exercise, Cholesterol Model Implies No Independence Relations
.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-53-1.png" width="70%" /&gt;
]
.pull-right[

```r
print( impliedConditionalIndependencies( gobs ) )
```
* C is a collider between `\(A\)` and `\(E\)`, but `\(A \rightarrow E\)` **shields** the collider, rendering `\(A\)` and `\(E\)` dependent even when `\(C\)` is not conditioned on

There is no way to test this model from observational data
]

---
## Independence (d-separation) Equivalence
.pull-left[
Two Causal DAGs over the same set of variables are independence equivalent iff they have:

* the same adjacencies (edges between variables ignoring direction)
* the same unshielded colliders (any two nodes pointing into the collider are not adjacent)
  * In graphs 1 and 3, `\(C\)` is a *shielded* collider, because `\(A\)` and `\(E\)` have an edge between them
  * If we deleted the edge between `\(A\)` and `\(E\)`, then `\(C\)` would be an unshielded collider

These graphs are all independence equivalent.  (Verma and Pearl, 1988)
]
.pull-right[
![](overview_causal_inference_files/figure-html/unnamed-chunk-55-1.png)&lt;!-- --&gt;
]
???
This concept is explained in detail in the following lecture at around 28 minutes:

From https://www.youtube.com/watch?v=TISSNwWDfw4&amp;list=PLO5mmwQolPRX858CyOOIHqYnmdzlHjIgS&amp;index=8

(CCD Summer short course 2016:Day 2 Part 1)

---
### CPDAG (Completed Partially Directed Acyclic Graph)
.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-56-1.png)&lt;!-- --&gt;
]
.pull-right[
A CPDAG represents an equivalance class of independence equivalent graphs

* A directed edge is shared by all graphs in the class
* An undirected edge is reversible as long as no cycles or additional unshielded colliders are introduced
]

---
### Age, Sex, Gender, BMI, and Cholesterol
.pull-left[
Hypothesized Graph

&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-57-1.png" width="70%" /&gt;
]
.pull-right[
CPDAG

![](overview_causal_inference_files/figure-html/unnamed-chunk-58-1.png)&lt;!-- --&gt;
]

---
class: middle, center
# Part III: Causal Discovery from Observational Data

---
# Inferring Causal Structure from Data

.center[Casual DAG `\\(\Rightarrow\\)` Independence Relations]

.pull-left[
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-59-1.png" width="70%" /&gt;
]

.pull-right[
.scroll-box-8[

```
bmigrp _||_ eageg | height, weight
bmigrp _||_ sex | height, weight
eageg _||_ sex
height _||_ hychol | bmigrp, eageg, sex
hychol _||_ weight | bmigrp, eageg, sex
```
]]

.center[Casual DAGS `\\(\Leftarrow\\)` Independence Relations]


---
exclude: true
### Results of the PC Algorithm (Spirtes and Glymour, 1991) On The WHO Monica Dataset 

.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-61-1.png)&lt;!-- --&gt;
]

.pull-right[
Graph implied by [Nature paper]
![](overview_causal_inference_files/figure-html/unnamed-chunk-62-1.png)&lt;!-- --&gt;
]

---
## Results of PC Algorithm on the WHO Dataset
.pull-left[
<div id="htmlwidget-76dfc1aa131811d1f3bd" style="width:504px;height:504px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-76dfc1aa131811d1f3bd">{"x":{"diagram":"digraph g {\n \"eageg\" -> \"height\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"weight\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"height\" -> \"weight\" [arrowtail=none, arrowhead=none]; \n \"height\" -> \"sex\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"bmigrp\" -> \"height\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"eageg\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"eageg\" -> \"hychol\" [arrowtail=none, arrowhead=none]; \n \"sex\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"eageg\" [dir=both, arrowtail=normal, arrowhead=none]; \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
]

.pull-right[
Graph implied by paper
![](overview_causal_inference_files/figure-html/unnamed-chunk-64-1.png)&lt;!-- --&gt;
]
???
The PC algorithm is one of the first causal discovery algorithms. As you can see from the inferred graph, many of the arrows are incorrect and some edges are not directional, meaning the algorithm could not orient the edge.

One limitation of PC (and most other algoirithms) is that the independence tests assume linear relationships. As a result, the algorithm will mistake nonlinearly dependent variables as independent.

See: Spirtes P, Glymour C. An algorithm for fast recovery of sparse causal graphs. Social science computer review. 1991 Apr;9(1):62-72.
---
## Adding Background Knowledge Improve Discovery


```r
# List of forbidden directed edges
forbid &lt;- list(c('chol', 'bmigrp'), c('eage', 'bmigrp'), c('weight', 'bmigrp'), c('sex', 'bmigrp'))

# List of required directed edges
require &lt;- list(c('eage','eageg'), c('bmi', 'bmigrp'), c('chol', 'hychol'), c('height', 'bmi'), c('weight', 'bmi'))

# Forbid edges between eage and sex
forbiddenWithin &lt;- c('eage','sex')
class(forbiddenWithin) &lt;- 'forbiddenWithin'

# Add Temporal constraints
temporal &lt;- list(forbiddenWithin, c('eageg','height', 'weight'), c('bmi', 'chol'), c('bmigrp', 'hychol')) 

prior &lt;- priorKnowledge(requiredirect = require, addtemporal = temporal, forbiddirect = forbid)
```
???
Since bmigrp is defined only by bmi, we forbid other variables from causing it. We could likewise forbid the two other defined variables in the dataset, eageg and hychol, but the algorithm works fine as is.

The temporal constraints indicate that lower tiers cannot have any directed edges to higher tiers. For instance, `bmi` and `chol` can have directed edges to `bmigrp` and `hychol`, as well as between themselves, but cannot have directed edges to the other variables that appear before them in the temporal list.
---
# Tetrad PC Algorithm with Knowledge
<div id="htmlwidget-faa2c16a857e6f9ba806" style="width:504px;height:504px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-faa2c16a857e6f9ba806">{"x":{"diagram":"digraph g {\n \"bmigrp\" -> \"hychol\" [arrowtail=none, arrowhead=none]; \n \"eageg\" -> \"height\" [arrowtail=none, arrowhead=normal]; \n \"height\" -> \"weight\" [arrowtail=none, arrowhead=none]; \n \"height\" -> \"sex\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"bmigrp\" -> \"height\" [dir=both, arrowtail=normal, arrowhead=none]; \n \"eageg\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"eageg\" -> \"hychol\" [arrowtail=none, arrowhead=normal]; \n \"sex\" -> \"weight\" [arrowtail=none, arrowhead=normal]; \n \"bmigrp\" -> \"eageg\" [dir=both, arrowtail=normal, arrowhead=none]; \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>

---
## Adding Knowledge: Required Edges

`TRUE` means the pair of variables must be connected by an edge



---
## Adding Knowledge: Forbidden Edges

A `\(1\)` means the row variable (e.g., `height`) must not have direct edge to the column variable (e.g., `bmi`)


---

### Results of the PC Algorithm With Background Knowledge 

.pull-left[

]

.pull-right[
Graph implied by [Nature paper]
![](overview_causal_inference_files/figure-html/unnamed-chunk-70-1.png)&lt;!-- --&gt;
]

---
# Associative vs. Causal Predictive Models
  
If we just want to predict, an associative predictive model is sufficient and may be better than a causal model.

Suppose diet affects weight and chol directly, but we don't know diet. BMI still allows us to predict chol in an associative model, but not intervene.

---
# Estimating Causal Expressions from Data

Adjustment stratifies data, which can lead to difficulties estimating causal expressions from actual (non-infinite) data

A number of statistical estimation methods are available

Propensity score example

---
### Modified Y Structure Equivalence Class
.pull-left[
Original Graph

&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-71-1.png" width="70%" /&gt;
]
.pull-right[
CPDAG

![](overview_causal_inference_files/figure-html/unnamed-chunk-72-1.png)&lt;!-- --&gt;
]

---
### Independence Implications Can be Tested Against a Dataset
.pull-left[
Original Graph


```
## U _||_ Z | X
## X _||_ Y | U, Z
```
]
.pull-right[
CPDAG

![](overview_causal_inference_files/figure-html/unnamed-chunk-74-1.png)&lt;!-- --&gt;
]

---
class: center, middle

## Part III: Counterfactual Reasoning

TBD soon

---
## Remaining slides are not part of the presentation

---
## Classic Definition of Confounder 
.pull-left[
A counfounder of `\(X\)` (the treatment) and `\(Y\)` (the outcome) is a variable `\(Z\)` that is

1. associated with `\(X\)`

2. is a cause of `\(Y\)`; and

3. does not reside on the causal pathway between `\(X\)` and `\(Y\)`
]
.pull-right[
Z is a confounder of `\(X \rightarrow Y\)`
![](overview_causal_inference_files/figure-html/unnamed-chunk-75-1.png)&lt;!-- --&gt;
]
???
This definition may be correct, though it is limited

reference for classical definition: Rothman KJ, Lash TL, Greenland S. Modern Epidemiology, 3rd ed. Philadelphia, PA: Lippincott Williams &amp; Wilkins; 2008. p. 195.

---


---
### Does Estrogen Replacement Therapy (ERT) Cause Uterine Cancer?
In the 1970's

- ERT widely prescribed to women after menopause
- Several studies found an association between ERT and uterine cancer
- ERT known to cause bleeding in some women
- Uterine cancer can cause bleeding

Two Hypotheses

- ERT causes uterine cancer
- ERT does not cause cancer, but causes bleeding, leading to a uterine exam, which increases the chance of finding undiagnosed uterine cancer

Yale researchers proposed limiting data analysis to women who have bled

Harvard researchers argued that such an analysis could find an association between ERT and Cancer even if ERT did not cause cancer

---
## Causal DAGs for each hypothesis
.pull-left[
![](overview_causal_inference_files/figure-html/unnamed-chunk-76-1.png)&lt;!-- --&gt;
]
---
## Adjust done at data collection or analysis (from Elwert)








---
## Causal DAGs and Joint Probability Distributions
Too complex. Use adjustment instead by showing how the observational dist for cholesterol can give the correct result when stratifying by age, as can regression when including Age as a covariate.

Then demonstrate why that doesn't always work by analyzing causal effect of age, discussing the total and direct effects from program, then that regression C ~ A + E only gives direct effect. So you must regress C ~ A to get total effect. In other words, you can't stratify by E for A.

Stratification is one way to adjust for variables to eliminate non-causal associations
.pull-left[
Any distribution generated by a Markovian causal DAG `\(M\)`, can be written as:

`$$P(v_1,v_2,...,v_n) = \prod_{i} P(v_{i}|pa_i)$$`

where `\(V_1, V_2,..., V_n\)` are the variables in `\(M\)`, and `\(pa_i\)` are the values of the parents of `\(V_i\)` in M.
]

.pull-right[
![](overview_causal_inference_files/figure-html/unnamed-chunk-77-1.png)&lt;!-- --&gt;

`$$P(a,e,c)=P(a)*P(e|a)*P(c|a, e)$$`
]

For example, the probability that a patient has A=50, E = 5, and C = 120 is given by:

`$$P(A=50,E=5,C=120)=P(a=50)*P(e=5|a=50)*P(c=120|a=50, e=5)$$`


.whisper[Technical notes: A graph is Markovian if there are no cycles and all error terms jointly indpendent.]

---
##Formal Definitions
For treatment X and outcome Y...
### Causal Effect
Value of Y given a specific intervention on X

  - Dichotomous (binary) outcomes: `\(P(Y=1|do(X = x)\)`

  - Continuous outcomes:  `\(E(Y|do(X=x))\)`
  
---
# Overadjustment Bias

---
# In General, No single multivariable regression can identify multiple causal effects

---
# Causal Inference Requires extra-Data Information
- There is not enough information in the data to determine causal effects
- An analyst must use a causal model
- Conclusions are always relative to the model

---
#Observational Results: Age and Exercise(!) Increase Cholesterol

.pull-left[
### Cholesterol vs Age
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-79-1.png" width="70%" /&gt;
`\(c = 99.92+0.2a \space (p&lt;.001)\)` (obs and int dist identical)
]
.pull-right[
### Wrong: Cholesterol vs Exercise
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-80-1.png" width="70%" /&gt;
]

---
## Intervening Changes the Generative Model
.pull-left[
Dichotomous Observational Generative Model

```r
n &lt;- 10000
g &lt;- rbinom(n, 1, .5)
*p_x_g &lt;- c(1/3, 2/3)
*x &lt;- rbinom(n, 1, p_x_g[g]) # Male: 1/3, Female: 2/3 
# gender  treatment p(heart attack)
#  male       0           .3
#  male       1           .4
# female      0           .05
# female      1           .07
p_h_gx = c(.3, .4, .05, .075)
h &lt;- rbinom(n, 1, p_h_gx[g*2+x+1])
```
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-82-1.png" width="100%" /&gt;
]
.pull-right[
Dichotomous Interventional Generative Model

```r
n &lt;- 10000
g &lt;- rbinom(n, 1, .5) 
*x &lt;- rbinom(n, 1, .5) # Random chance
#          m¬t  mt  f¬t  ft
p_h_gx = c(.3, .4, .05, .075) # p(H|M,T)
h &lt;- rbinom(n, 1, p_h_gx[g*2+x+1])
```
&lt;img src="overview_causal_inference_files/figure-html/unnamed-chunk-84-1.png" width="100%" /&gt;

```r
# CPT of h given g and x
p_h = dint %&gt;% group_by(G, X) %&gt;% summarise(p_h = sum(H == 1)/n())
xtabs(p_h ~ G+X, p_h)
```

```
##    X
## G            0          1
##   0 0.29882734 0.40855107
##   1 0.05290792 0.07762376
```
]

---
P(h|g,x)

```r
# CPT of h given g and x, with marginals
p_h = dint %&gt;% group_by(G, X) %&gt;% summarise(p_h = sum(H == 1)/n())
addmargins(xtabs(p_h ~ G+X, p_h))
```

```
##      X
## G              0          1        Sum
##   0   0.29882734 0.40855107 0.70737840
##   1   0.05290792 0.07762376 0.13053168
##   Sum 0.35173525 0.48617483 0.83791008
```

---
## GGPlotly graph
<div id="htmlwidget-d736885b0dfaa8bfff7d" style="width:100%;height:504px;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-d736885b0dfaa8bfff7d">{"x":{"url":"overview_causal_inference_files/figure-html//widgets/widget_unnamed-chunk-87.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
